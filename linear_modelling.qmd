---
title: "Linear modelling in ecology"
bibliography: references.bib
execute: 
  freeze: auto
output: 
  html_document:
   toc: true
   toc_float: true
---

This chapter is a simple example using R

You can import R package using the code

```{r}
library(tidyverse)
```


and then describe the purpose of your chapter as well as executing R command.


For example a basic summary of a dataset is given by 

```{r}
df <- read.table("https://gist.githubusercontent.com/slopp/ce3b90b9168f2f921784de84fa445651/raw/4ecf3041f0ed4913e7c230758733948bc561f434/penguins.csv", sep = "," , header = TRUE)
```

and produce a graph

```{r}
df %>% ggplot() +
	aes(x=species, y = body_mass_g) +
	geom_boxplot()  
```


A citation @bauer2023writing

Au sein de chaque groupe, on peut créer des branches pour répartir le travail de rédaction.

Intro #Fanny

I. Modèles linéaires généraux
1) ANOVA #Clément
2) ANCOVA #Lucia
3) Régression #Fanny
4) Validation des modèles #Lucia

II. Modèles linéaires généralisés
1) Loi binômiale #Sarah
2) Loi de Poisson #Léa
```{r}
#Load R packages
rm(list=ls()) # Properly clear workspace
library(knitr)
opts_chunk$set(echo = FALSE, comment = "", cache = TRUE, fig.align = "center")
library(ggplot2) # graph package
library(DHARMa)# Model diagnosis
library(rcompanion)# Model pseudo R²
library(lattice)# multipanel graphics
library(MASS)
```

II/ Generalized linear models 

  1)	Poisson law
  
Here we will focus on count data. This count data is a positive discrete variable. There are two types of distribution for this type of data. It can follow a Poisson or a Negative Binomial law.  We will first focus on a Poisson law. 

For the Poisson law, we have :  $$ E(y)= Var(y)=\lambda $$

We can write the distribution under a Poisson distribution as follows: 

$$Pr(Y=y)=\frac{e^{-\lambda}.\lambda^y}{y!}$$

$y$ permit to count the number of occurrences and $\lambda$ is the mean and the variance of the Poisson distribution

The link function of the Poisson law in the Generalized Linear model is **log** and can be written like that : 

$$log(\mu_{y})= \alpha+ \beta_{1}.X{i1}+ \beta_{2}.X{i2}+\beta_{3}.X{i3}+...\beta_{p}.X{ip} = \eta $$

By applying the inverse link function to $\eta$, we obtain the predicted values of Y : 
$$\mu_{y}= e^{\alpha+ \beta_{1}.X{i1}+ \beta_{2}.X{i2}+\beta_{3}.X{i3}+...\beta_{p}.X{ip}} = e^{\eta} $$ 
Let’s take an example to illustrate the use of the Poisson law : 

# Example with the Poisson law 

## DATA DESCRIPTION AND OBJECTIVES 

The study of Gotelli and Ellison in 2002 is a good example to apply the Poisson law. It is named “Biogeography at a regional scale: determinants of ants species density in New England bogs and forests”. At each of 22 sites, 25 pitfall traps were set in two 8x8m arrays, one in the center of the bog and one in adjacent upland forest 50 to 500m from the corresponding bog. Traps are treated as 50 independent replicate observations. The data are in the file BogAnts.txt. 

```{r}
# Dataset importation 
ants<-read.table("BogAnts.txt", dec = ".", header = TRUE) 
ants$Location<-as.factor(ants$Location)
str(ants)

# Check for presence of missing values
colSums(is.na(ants))
# There is no missing value.

```

We have 6 variables. The first one gives the site name. Latitude, Area (of the bog) and Elevation are covariates for each site. Location is a qualitative variable (‘Bog’ or ‘Forest’). The response variable is the last one variable (Nsp) which give the number of ant species found in the traps, in other words the ant species richness. 

For this research we can wonder : which continuous or categorical variables drive the species richness of ants in bogs from New England ? 

As said previously, before any analysis, you must explore the data, but we are not going to do this here. 
However, before continuing, we need to transform the variable 'Area', as in the exploration we can see a presence of outliers due to presence of very extensive bogs. We will therefore perform a log-transformation of this covariate. 

```{r}
par(mfrow=c(1,3))
# Bog Area
# Cleveland plot
dotchart(ants$Area,pch=16,col='blue',xlab='Bog Area')
# Histogram
hist(ants$Area,col='blue',xlab="Bog Area",main="")
# Quantile-Quantile plot
qqnorm(ants$Area,pch=16,col='blue',xlab='')
qqline(ants$Area,col='red')
```
```{r}
par(mfrow=c(1,3))

# Log-transformation for the 'Area' variable : 
ants$LogArea<-log(ants$Area)

# Log Bog Area
# Cleveland plot
dotchart(ants$LogArea,pch=16,col='blue',xlab='LogBog Area')
# Histogram
hist(ants$LogArea,col='blue',xlab="LogBog Area",main="")
# Quantile-Quantile plot
qqnorm(ants$LogArea,pch=16,col='blue',xlab='')
qqline(ants$LogArea,col='red')
```

Now we can use the ‘Area’ variable. 

## STATISTICAL ANALYSIS

### Model building

As every model building, we will search for the candidate model by first analysing the full model with all the independent variables and their interactions. Then a backward selection will be used to select the best model based on term significance. Successively, the non-significant interactions are deleted, and then the non-significant main effects. However, a non-significant main effect is deleted only if it is non-significant AND not contained in a significant interaction. 

Here we perform a Poisson generalized linear model with these code lines : 

```{r}
# The model is : 
mod1<-glm(Nsp~ Location
        + Latitude
        + Elevation
        + LogArea
        + Location:Latitude
        + Location:Elevation
        + Location:LogArea
        ,data=ants
        ,family=poisson(link="log"))
# To check the significance
drop1(mod1,test="Chi")
```

Here any interaction is significant. We delete the less significant interaction : Location:Latitude and do this code lines until there are only significant effects. 

```{r}
# The model is : 
mod1<-glm(Nsp~ Location
        + Latitude
        + Elevation
        + LogArea
        + Location:Elevation
        + Location:LogArea
        ,data=ants
        ,family=poisson(link="log"))
# To check the significance
drop1(mod1,test="Chi")
```

The less significant interaction is Location:LogArea. So we delete this interaction and continue. 

```{r}
# The model is : 
mod1<-glm(Nsp~ Location
        + Latitude
        + Elevation
        + LogArea
        + Location:Elevation
        ,data=ants
        ,family=poisson(link="log"))
# To check the significance
drop1(mod1,test="Chi")
```

The less significant interaction is Location:Elevation. So, we delete this interaction and continue. 

```{r}
# The model is : 
mod1<-glm(Nsp~ Location
        + Latitude
        + Elevation
        + LogArea
        ,data=ants
        ,family=poisson(link="log"))
# To check the significance
drop1(mod1,test="Chi")
```

The less significant effect is LogArea. So, we delete this effect and continue. 

```{r}
# The model is : 
mod1<-glm(Nsp~ Location
        + Latitude
        + Elevation
        ,data=ants
        ,family=poisson(link="log"))
# To check the significance
drop1(mod1,test="Chi")
```
Here all the effects are significant. So we can stop the backward selection and conclude with this the selected model: Nsp~Location + Elevation + Latitude 

It is necessary to analyse the coefficients of the model in order to understand how the main effects influence the ant species richness in bogs. 

### Model's coefficients analysis
```{r}
# Coefficients of the model
summary(mod1)
```

So we can write the model like that: 
$$ log(Species\:Richness) = 11.93 + (Location_{Bog} = 0 ;\:Location_{Forest} = +0.63^{***})\:- 0.23^{***}.Latitude\: -0.001^{***}. Elevation  $$
Be careful here, for a factor, there is a level call “the baseline” which mean that its coefficient is 0. It is the reference level. 

### Model explanation

In generalized linear models, there is no R2, so we need to calculate a pseudo R2 with the distance between the null model deviance and the residual deviance of the model with this formula: 
$$Pseudo\:R^2=100\:.\:\frac{Null\:Deviance- Residual\:Deviance}{Null\:Deviance}$$ 

Let’s do it with R : 

```{r}
# Pseudo R2 calculation 
(mod1$null.deviance-mod1$deviance)/mod1$null.deviance

# We can have other pseudo R2 with the package 'rcompanion'
nagelkerke(mod1)
```

So here, the model explains 60.4% of the deviance, but with the others estimate, we found the model explain about 75% of the deviance. 
Now, it is necessary to check the assumptions of the model to validate. See the part dedicated to this at the end.

2) Loi négative binômiale #Léa

The Negative Binomial distribution has been parameterized in a number of different ways in the statistical literature. Perhaps the most common way to parameterize is to see the Negative Binomial distribution arising as a distribution of the number of failures (X) before the r^th success in independent trials, with success probability p in each trial (consequently, r > 0 and 0 < p > 1). In such a case the probability mass function can be expressed as :

$$Pr(X=x|r,p)=\frac {\Gamma(x+r)}{x!.\Gamma(r)}.p^r.(1-p)^x$$
and the random variable X has the expectation (theoretical mean):

$$\mu =\frac{r.(1 - p)}{p}$$ 

and variance

$$\sigma^2 = \frac{r.(1 – p)}{p^2}$$

In a NB Generalized Linear model, the link function is log so that

$$log(\mu_{y})= \alpha+ \beta_{1}.X{i1}+ \beta_{2}.X{i2}+\beta_{3}.X{i3}+...\beta_{p}.X{ip} = \eta $$

The predicted values of Y is obtained by applying the inverse link function to η.

$$\mu_{y}= e^{\alpha+ \beta_{1}.X{i1}+ \beta_{2}.X{i2}+\beta_{3}.X{i3}+...\beta_{p}.X{ip}} = e^{\eta} $$

The negative binomial model has a NB error structure. This error structure allows, among other things, to correctly specify the relationship between the mean and the variance. This relationship is used by the maximum likelihood approach to estimate the coefficients and standard errors of the generalized linear model parameters.

Let’s take an example to illustrate the use of the Negative binomial law : 

# Example with the Negative binomial law 

## DATA DESCRIPTION AND OBJECTIVES  
The study of Timi and Poulin in 2003 is a good example to apply the Negative binomial law. We will use a subset of the original data. At each of 4 stations, fish sample were collected, with a total of 522 individual of anchovy. These fish were examined for parasites in order to understand the parasite community structure across the host population of anchovy. The data are in the file FishParasite.txt
The response variable is “Number”, which represents the total number of parasites found in the fish. It is a count variable. There are 3 explicative variables: “Sex” (of the fish), “Length” (of the fish) and “Area”. Sex and Length are continuous, and Area is a categorical variable with 4 categories (A, B, C or D). Here we only consider the interaction between Length and Area. 

```{r}
# Dataset import
para <- read.table("FishParasites.txt", dec=".", header = TRUE)
para$Area<-as.factor(para$Area)
para$Sex<-as.factor(para$Sex)
str(para)
# Missing values ? 
colSums(is.na(para))
# There is no missing value.
```

Let’s begin quickly with a Poisson model in order to see the problems and then apply a Negative Binomial model. 

As said previously, before any analysis, you must explore the data, but we are not going to do this here.

We perform a backward selection as explained previously, with a Poisson model : 

```{r}
# Model formulation
mod1<-glm(Number~ Sex
        + Area
        + Length
        + Area:Length
        ,data=para
        ,family=poisson(link="log"))
# Then we check for significance
drop1(mod1,test="Chi")
summary(mod1)
```

Here the interaction between Length and Area is significant, so we keep both variables. And Sex is also significant. So the full model is the candidate model. To see if we can apply the Poisson model, we test the overdispersion. Sometimes, the variance of the response variable may be higher than supposed by the Poisson law. If the parameter is greater than 1.5, we can say that there is overdispersion and the standard errors of the coefficient estimates are biased. 
Let’s check the overdispersion in the model with a DHARMa non parametric dispersion test: 

```{r}
# Overdisperion checking of the Poisson model
# Scale parameter calculation
E1 <- resid(mod1, type = "pearson") # (Y - mu) / sqrt(mu)
N  <- nrow(para)
p  <- length(coef(mod1))
sum(E1^2) / (N - p)

# Use simulations for parameter estimation (package DHARMa)
testDispersion(mod1)
```

The overdispersion index is largely over 1.5, which means that there is an overdispersion in the model. So, the Poisson model can’t be apply and analyse. 
There are some reasons of overdispersion like for example: the presence of outliers, a dependency, a non linear relationship, the use of the wrong link function… 

We will change and use a Negative Binomial model and recalculate the overdispersion once we have found the model. 

```{r}
# Model formulation
modNB<-glm.nb(Number~ Sex
        + Area
        + Length
        + Area:Length
        ,data=para)
# Then we check for significance
drop1(modNB,test="Chi")
```
We have a significant effect for the interaction between Area and Length but not for the main effect Sex. We need to keep the main factor Area and Length and delete the variable Sex, contrary to the Poisson model. 

```{r}
# Model formulation
modNB<-glm.nb(Number~ Area
        + Length
        + Area:Length
        ,data=para)
# Then we check for significance
drop1(modNB,test="Chi")
```
Here, the interaction is still significant, with the two main effect. So we have found the candidate model. Now we need to test the overdispersion, the same way as before. 

```{r}
# Overdisperion checking of the NB model
# Scale parameter calculation
E1 <- resid(modNB, type = "pearson") # (Y - mu) / sqrt(mu)
N  <- nrow(para)
p  <- length(coef(modNB))
sum(E1^2) / (N - p)

# Use simulations for parameter estimation (package DHARMa)
testDispersion(modNB)
```
We found 1.35, which is below/under 1.5. So we succeed to delete the overdispersion. The DHARMa test validates the absence of overdispersion. 

### Model explanation

Now we can examine the coefficients of the candidate model in order to understand how the number of parasites in fish is influenced.

```{r}
# Coefficients of the model
summary(modNB)
```


So, the candidate model is:
$$ log(Number\:of\:Parasites) = -0.44 + (Area_{A} = 0 ;\:Area_{B} = +1.64;\:Area_{C} = -0.61;\:Area_{D}  = -5.42)$$ 
$$ +\: 0.028.Length\:+ (if\:Area=B: - 0.010. Length;\:if\:Area=C: + 0.002. Length ;\:if\:Area=C: + 0.029.Length)  $$

Be careful here! As we saw previously, there is always a modality of the factor which is the baseline, and every modality of this factor is compared to the baseline. So if a modality of the factor is significant, it means that there is a difference between this modality and the baseline. So in order to test which modality is different from one another, we need to change the baseline. 

As in every Generalized Linear Models, there is no R2. So we will calculate the pseudo R2 with the formula : 

$$Pseudo\:R^2=100\:.\:\frac{Null\:Deviance- Residual\:Deviance}{Null\:Deviance}$$

On R : it is : 

```{r}
# Estimate of deviance explained
(modNB$null.deviance-modNB$deviance)/modNB$null.deviance

# Some others estimates of deviance explained - package 'rcompanion'
nagelkerke(modNB)
```

4) Validation des modèles #Clément

Conclusion #Sarah

Remarques :
-ici on ne parle pas de partie Exploration des données
-on ne parle pas de Gamma mais il faudra la mentionner (signaler qu'elle existe mais pas dans le programme M2)
