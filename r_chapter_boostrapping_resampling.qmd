---
title: "Chapter : Bootstrapping and Resampling"

bibliography: references.bib
execute: 
  freeze: auto
output: 
  html_document:
   toc: true
   toc_float: true
---

------------------------------------------------------------------------

title: "Chapter : Bootstrapping and Resampling"

bibliography: references.bib \# Fichier bibliographie execute: freeze: auto output: html_document: toc: true toc_float: true ---

# General introduction

A dataframe:

```{r}
data <- iris
head(iris)
```

## Confidence interval on a sample

Peut-on estimer la taille moyenne

```{r}

hist(data$Sepal.Width)
shapiro.test(data$Sepal.Width)
qqnorm(data$Sepal.Width)
qqline(data$Sepal.Width)
#Or iris dataset ? 
```

L'échantillon est normalement distribué, on peut donc calculer l'intervalle de confiance de la moyenne de la manière suivante:

```{r}
low <- mean(data$Sepal.Width)-1.96*sd(data$Sepal.Width)/sqrt(length(data$Sepal.Width))
high <- mean(data$Sepal.Width)+1.96*sd(data$Sepal.Width)/sqrt(length(data$Sepal.Width))
print(c(low,high))
```

rq: source INSEE taille moyenne F = 1 m 62, et https://ourworldindata.org/grapher/average-height-by-year-of-birth?time=latest&country=\~FRA taille moyenne = 1m6488 pour les gens nés en 1996 (pas de date après) Not in intervall, pop grow, + ech non représentatif de la pop française

## Confidence interval on multiple sub-samples means

Si on veut désormais estimer $\mu$, la taille moyenne des étudiants sur les trois promotions du jeu de données.

```{r}
(mu <- mean(data$Sepal.Width))
```

mu correspond à la taille moyenne qu'on veut estimer mais dont on ne connait pas la véritable valeur.

# The Jackknife resampling method

Imaginons mantenant que nous ayons seulement accès à un échantillon et qu'on veuille estimer la taille moyenne des étudiants de ces trois promotions.

```{r}
set.seed(121)
data_sample <- data[sample(1:150,30),]
mean(data_sample$Sepal.Width)
hist(data_sample$Sepal.Width)
shapiro.test(data_sample$Sepal.Width)
qqnorm(data_sample$Sepal.Width)
qqline(data_sample$Sepal.Width)
```

On a seulement accès à cet échantillon non normalement distribué. La dessus, nous ne pouvons pas calculer les intervalles de confiance comme vu précedemment. C'est là que je Jackknife devient intéressant.

...

## a - Principe

## b - exemple d'implémentation

test pas du tout fini

```{r}
group <- c()
sampled_data <- c()
for (i in 1:20) { #au total, 100 individus auront été échantillonnés
  set.seed(i)
  sample_temp <- sample(setdiff(1:139,sampled_data),5)
  sampled_data <- c(sampled_data,sample_temp)
  group <- c(group,mean(data[sample_temp,"Sepal.Width"]))
  
}
```

```{r}
hist(group)
qqnorm(group)
qqline(group)
shapiro.test(group)
```

## c - Avantages et inconvénients de la méthode

# Tests de permutation

## Introduction

Les tests de permutations sont une méthode statistique puissante pour comparer des groupes et évaluer l'effet d'une variable sur une autre. Contrairement aux tests paramétriques, les tests de permutations ne reposent pas sur des hypothèses spécifiques concernant la distribution des données, les rendant ainsi plus robustes dans certaines situations. Autrement dit, même si les données de notre échantillon ne suive pas une loi classique (e.g. gaussienne), l'inférence statistique reste possible. Ce sont des tests dont le fonctionnement est intuitifs, facile à mettre en place et leur robustenne les rend particulièrement pratique dans un grand nombre de situations.

## Fondements des Tests de Permutations

### Principe Fondamental

A l'instar des autres tests statistiques classiques (e.g. T de Student, test du $\chi 2$ ...), les tests de permutations sont basés sur une distribution d'une statistique de test sous l'hypothèse nulle. La distribution sous l'hypothèse nulle correspond à la distribution théorique de la statistique du test en supposant que l'effet que nous testons n'a pas d'impact (i.e. que nos variables explicatives n'ont pas d'effet sur la variable dépendante). Dans les tests statistiques classiques, cette distribution correspond à différentes lois connues, la plus connue étant la loi Gaussienne, mais ça peut-être la distribution de Student, la distribution $\chi 2$ etc. La particularité des tests de permutations est que l'on va générer cette distribution théorique de façon empirique directement à partir des données. Les tests de permutation sont des tests non-paramétriques (ils ne font pas d'approximation de distribution) et exacts (basés sur les données uniquement).

Selon les règles du théorème centrale limite, répéter un grand nombre de fois une observation d'une variable aléatoire (ici la statistique de test) ménera à une distribution Gaussienne dans laquelle on pourra placer la statistique de test observée (i.e. calculée sur notre échantillon) et ainsi définir la significativité de l'effet de nos variables explicatives. En d'autres termes, on génère toutes les permutations possibles des observations, calculons la statistique de test pour chaque permutation, puis comparons la statistique observée à cette distribution nulle.

### Statistique de Test

La statistique d'un test est une mesure numérique utilisée pour évaluer si les différences observées entre les groupes dans une étude sont statistiquement significatives. Elle permet de quantifier l'écart entre les observations observées et celles qui pourraient être attribuées au hasard. Voici quelques exemples de statistiques de tests connues : \$\$ \begin{align*}
F [\text{ANOVA}] &: \quad F = \frac{MS_{\text{intergroupes}}}{MS_{\text{intragroupes}}} \quad \sim \mathcal{F(ddl_{\text{intergroupes}}, ddl_{\text{intragroupes}})} &&\\
\\
t [\text{t de Student}] &: \quad t = \frac{\bar{X}_1 - \bar{X}_2}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}} \quad \sim t(ddl) &&\\
\\
\chi^2 [\text{Test du } \chi^2] &: \quad \chi^2 = \sum \frac{(O_i - E_i)^2}{E_i} \quad \sim \chi^2(ddl) &&\\
\end{align*}

\$\$ Avec $MS$ l'erreur moyenne carrée, $ddl$ le degré de liberté, $\bar{X}_i$ la moyenne du groupe $i$, $s^2_i$ la variance du groupe $i$, $n_i$ le nombre de réplicats du groupe $i$, $O_i$ la distance $\chi^2$ observée, $E_i$ la distance $\chi^2$ attendue.

Ces statistiques suivent des loi de distribution connues, on va donc comparer la statistique observée (calculé sur l'échantillon de données) à la distribution nulle de cette statistique et obtenir ainsi une p-valeur.

Ces staomme La statistique de test pour les tests de permutations dépend du type d'étude et de la relation entre les données (indépendance ou non-indépendance). Pour un test de différence de moyennes entre deux groupes, par exemple, la statistique de test pourrait être définie comme suit :

\[ T = \frac{\bar{X}_1 - \bar{X}_2}{s_{\text{pooled}}} \sqrt{\frac{n_1 n_2}{n_1 + n_2}}, \]

où (\bar{X}\_1) et (\bar{X}*2) sont les moyennes des deux groupes, (s*{\text{pooled}}) est l'écart-type combiné des groupes, et (n_1) et (n_2) sont les tailles des échantillons.

## Mise en œuvre des Tests de Permutations

### Étapes du Test

Les étapes typiques pour mettre en œuvre un test de permutations comprennent :

1.  Formuler les hypothèses nulle et alternative.
2.  Calculer la statistique de test à partir des données observées.
3.  Générer toutes les permutations possibles des données.
4.  Calculer la statistique de test pour chaque permutation.
5.  Comparer la statistique observée à la distribution nulle des statistiques de test.
6.  Conclure sur l'acceptation ou le rejet de l'hypothèse nulle.

## Exemples Pratiques

### Test de Permutations pour la Différence de Moyennes

Considérons un exemple où nous voulons tester si la différence de moyennes entre deux groupes est statistiquement significative. La statistique de test est définie comme dans l'équation ci-dessus.

### Test de Permutations pour la Corrélation

Dans le cas d'une corrélation, la statistique de test pourrait être basée sur la mesure de corrélation de Spearman. Les étapes décrites précedemment devront être suivi également.

# Regressions and Mantel tests

## Regressions

Regression is a method of empirically modeling a response variable (here called $Y$) as a function of one or more explanatory variables ( $X_1,X_2,.,X_n$ where $n$ is the number of explanatory variables). Linear regressions are the ones most commonly used in statistics, mainly because they are easy to apply. Let's place ourselves in this linear world. The linear model is modelled by :

$$ 
Y_i = \alpha + \sum_{j=1}^{n}b_j \times X{ij} +\epsilon\_i\sim\mathcal{N}(0,,\sigma)
$$ {#eq-1}

With $Y_i$ the $i^{th}$ value of the variable $Y$ and $X_{ij}$ the $i^{th}$ value of the $j^{th}$ variable $X$.

### Statistical test on the coefficients.

We now need to make sure that the parameters \$b\$ and $\alpha$ are different from 0. The permutation test is used to define the null hypothesis (H0: $\alpha=0$ and $b = 0$). The idea is to permute the values of

$Y_i$ with respect to $X_ij$ or vice versa.

```{r exemple permutation sepal.width & sepal.length}
library(kableExtra) # Mettre en 1er chunk si nécessaire
library(knitr)
library(dplyr)
library(tidyverse)

data <- iris[1:10,] # sous échantillon de iris

permu <- data.frame(echantillon.y = rep(NA, nrow(data)),
                    echantillon.x = rep(NA, nrow(data)))

samp_ind <- sample(1:nrow(data), nrow(data))

permu$echantillon.y <- data$Sepal.Length[samp_ind]
permu$echantillon.x <- data$Sepal.Width

cbind(data[,1:2], permu) %>%
  kable("html", booktabs =TRUE, align = rep("c", 4)) %>%
  add_header_above(c("Sepal" = 2, "echantillon" = 2), bold = TRUE)%>%
  kable_paper("hover", full_width = F)
  
```

For each permutation, a linear model is constructed. The set of parameters estimated from the permuted samples form H0. The parameter b is estimated by the method of least squares such that :

$$
b_i=\frac{\sum(x_i-\bar{x})(y_i-\bar{y})}{\sum(x_i-\bar{x})}
$$

The parameter $\alpha$ is estimated by : 
$$
\alpha=\bar{y}-b_i\bar{x}
$$



```{r}

n_permu <- 1000 # choice of number of permutations

hyp_nulle <- matrix(NA, nrow = n_permu, ncol = 2)
colnames(hyp_nulle) <- c("alpha", "b")

permu <- matrix(NA, ncol = n_permu, nrow = nrow(data))


for (i in 1:n_permu){
# random sampling
samp_ind <- sample(1:nrow(data), nrow(data))

# creation of samples, we permute the Ys with respect to the Xi
permu[,i] <- data$Sepal.Length[samp_ind]


#Coefficients estimation
hyp_nulle[i,1] <- lm(permu[,i]~data$Sepal.Width)$coefficients[[1]]
hyp_nulle[i,2] <- lm(permu[,i]~data$Sepal.Width)$coefficients[[2]]
}

# Distribution of the null hypothesis

par(mfrow = c(1,2))
hist_1 <- hist(hyp_nulle[,1], 
     main = expression("Empirical distribution of "*alpha*" under H0"),
     xlab = expression(""*alpha*"")) 
hist_2 <- hist(hyp_nulle[,2], 
     main = expression("Empirical distribution of b under H0"),
     xlab = "b")



```

### observed regression coefficients

```{r}

# Calcul des coefficients de la regression à partir des données brutes
obs <- lm(data$Sepal.Length~data$Sepal.Width)$coefficients 

# Distribution de H0 et coefficients observés

par(mfrow = c(1,2))
plot(hist_1,
     main = expression("Distribution empirique de "*alpha*" sous H0"),
     xlab = expression(""*alpha*"")) 
abline(v = obs[1])

plot(hist_2,
     main = expression("Distribution empirique de b sous H0"),
     xlab = expression("b")) 
abline(v = obs[2])



```

# Calculation of test statistics

```{r}

p_a <- length(hyp_nulle[hyp_nulle[,1]<=obs[1]])

p_value_a <- p_a/n_permu

p_b <- length(hyp_nulle[hyp_nulle[,2]>=obs[2]])

p_value_b <- p_b/n_permu

#results representation

df_results <- data.frame(alpha = round(c(obs[1], p_value_a),10),
                         b = round(c(obs[2], p_value_b),4))
row.names(df_results) <- c("coefficient \n observed", "P value")

df_results%>%
  kable("html", booktabs =TRUE, align = rep("c", 3))%>%
  kable_paper("hover", full_width = F)
  
```

## Mantel test

### Uses

The Mantel test (Mantel, 1967) is used to evaluate the relationship between two matrices of correspondences measured on the same individuals. The two correspondence matrices (or distances) are denoted by $X$ and $Y$. Here, the null hypothesis describes the independence of the mechanisms governing the distances between individuals. The H0 distribution is obtained by permuting the individuals between them.

### Correspondence matrices (distances)

Distance matrices must relate to the same individuals. You can use the vegan package to extract them from a dataset. Here, we use a dataset from the UCLA site.

```{r}
library(vegan)

# Download a dataset and create distance matrices
ozone <- read.table("https://stats.idre.ucla.edu/stat/r/faq/ozone.csv", sep=",", header=T)
station.dists <- dist(cbind(ozone$Lon, ozone$Lat))
ozone.dists <- dist(ozone$Av8top)

station.dists <- as.matrix(station.dists)[1:5, 1:5]
ozone.dists <- as.matrix(ozone.dists)[1:5, 1:5]
ozone.dists <- cbind(c("1","2","3","4","5"),as.data.frame(ozone.dists))

names(ozone.dists) <- c("","1","2","3","4","5")
ozone.dists %>% # Visualizing a distance matrix
  kable("html", booktabs =TRUE, align = rep("c", 6))%>%
  kable_minimal()%>%
  column_spec(1, bold = TRUE)

```

There are a number of packages available to perform the Mantel test. For example, the ade4 package 


```{r}
# Using the ade4 package

library(ade4)

mantel.rtest(as.dist(station.dists), as.dist(ozone.dists), nrepet = 99)
```


The vegan package allows you to use different statistics. In our case we chose the Pearson correlation.

```{r}
# Using the vegan package, pearson correlation
mantel(xdis = station.dists, ydis = ozone.dists, permutations = 99)
```

With this funcions, you can get the p-value (significiance) of the nul hypothesis.
