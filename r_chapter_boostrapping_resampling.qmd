---
title: "Chapter : Bootstrapping and Resampling"

bibliography: references.bib
execute: 
  freeze: auto
output: 
  html_document:
   toc: true
   toc_float: true
---

------------------------------------------------------------------------

title: "Chapter : Bootstrapping and Resampling"

bibliography: references.bib \# Fichier bibliographie execute: freeze: auto output: html_document: toc: true toc_float: true ---

# General introduction

A dataframe:

```{r}
data <- iris
head(iris)
```

## Confidence interval on a sample

Peut-on estimer la taille moyenne

```{r}

hist(data$Sepal.Width)
shapiro.test(data$Sepal.Width)
qqnorm(data$Sepal.Width)
qqline(data$Sepal.Width)
#Or iris dataset ? 
```

L'échantillon est normalement distribué, on peut donc calculer l'intervalle de confiance de la moyenne de la manière suivante:

```{r}
low <- mean(data$Sepal.Width)-1.96*sd(data$Sepal.Width)/sqrt(length(data$Sepal.Width))
high <- mean(data$Sepal.Width)+1.96*sd(data$Sepal.Width)/sqrt(length(data$Sepal.Width))
print(c(low,high))
```

rq: source INSEE taille moyenne F = 1 m 62, et https://ourworldindata.org/grapher/average-height-by-year-of-birth?time=latest&country=\~FRA taille moyenne = 1m6488 pour les gens nés en 1996 (pas de date après) Not in intervall, pop grow, + ech non représentatif de la pop française

## Confidence interval on multiple sub-samples means

Si on veut désormais estimer $\mu$, la taille moyenne des étudiants sur les trois promotions du jeu de données.

```{r}
(mu <- mean(data$Sepal.Width))
```

mu correspond à la taille moyenne qu'on veut estimer mais dont on ne connait pas la véritable valeur.

# The Jackknife resampling method

Imaginons mantenant que nous ayons seulement accès à un échantillon et qu'on veuille estimer la taille moyenne des étudiants de ces trois promotions.

```{r}
set.seed(121)
data_sample <- data[sample(1:150,30),]
mean(data_sample$Sepal.Width)
hist(data_sample$Sepal.Width)
shapiro.test(data_sample$Sepal.Width)
qqnorm(data_sample$Sepal.Width)
qqline(data_sample$Sepal.Width)
```

On a seulement accès à cet échantillon non normalement distribué. La dessus, nous ne pouvons pas calculer les intervalles de confiance comme vu précedemment. C'est là que je Jackknife devient intéressant.

...

## a - Principe

## b - exemple d'implémentation

test pas du tout fini

```{r}
group <- c()
sampled_data <- c()
for (i in 1:20) { #au total, 100 individus auront été échantillonnés
  set.seed(i)
  sample_temp <- sample(setdiff(1:139,sampled_data),5)
  sampled_data <- c(sampled_data,sample_temp)
  group <- c(group,mean(data[sample_temp,"Sepal.Width"]))
  
}
```

```{r}
hist(group)
qqnorm(group)
qqline(group)
shapiro.test(group)
```

## c - Avantages et inconvénients de la méthode

# Tests de permutation

## Introduction

Les tests de permutations sont une méthode statistique puissante pour comparer des groupes et évaluer l'effet d'une variable sur une autre. Contrairement aux tests paramétriques, les tests de permutations ne reposent pas sur des hypothèses spécifiques concernant la distribution des données, les rendant ainsi plus robustes dans certaines situations. Autrement dit, même si les données de notre échantillon ne suive pas une loi classique (e.g. gaussienne), l'inférence statistique reste possible. Ce sont des tests dont le fonctionnement est intuitifs, facile à mettre en place et leur robustenne les rend particulièrement pratique dans un grand nombre de situations.

## Fondements des Tests de Permutations

### Principe Fondamental

A l'instar des autres tests statistiques classiques (e.g. T de Student, test du $\chi 2$ ...), les tests de permutations sont basés sur une distribution d'une statistique de test sous l'hypothèse nulle. La distribution sous l'hypothèse nulle correspond à la distribution théorique de la statistique du test en supposant que l'effet que nous testons n'a pas d'impact (i.e. que nos variables explicatives n'ont pas d'effet sur la variable dépendante). Dans les tests statistiques classiques, cette distribution correspond à différentes lois connues, la plus connue étant la loi Gaussienne, mais ça peut-être la distribution de Student, la distribution $\chi 2$ etc. La particularité des tests de permutations est que l'on va générer cette distribution théorique de façon empirique directement à partir des données. Les tests de permutation sont des tests non-paramétriques (ils ne font pas d'approximation de distribution) et exacts (basés sur les données uniquement).

Selon les règles du théorème centrale limite, répéter un grand nombre de fois une observation d'une variable aléatoire (ici la statistique de test) ménera à une distribution Gaussienne dans laquelle on pourra placer la statistique de test observée (i.e. calculée sur notre échantillon) et ainsi définir la significativité de l'effet de nos variables explicatives. En d'autres termes, on génère toutes les permutations possibles des observations, calculons la statistique de test pour chaque permutation, puis comparons la statistique observée à cette distribution nulle.

### Statistique de Test

La statistique d'un test est une mesure numérique utilisée pour évaluer si les différences observées entre les groupes dans une étude sont statistiquement significatives. Elle permet de quantifier l'écart entre les observations observées et celles qui pourraient être attribuées au hasard. Voici quelques exemples de statistiques de tests connues : \$\$ \begin{align*}
F [\text{ANOVA}] &: \quad F = \frac{MS_{\text{intergroupes}}}{MS_{\text{intragroupes}}} \quad \sim \mathcal{F(ddl_{\text{intergroupes}}, ddl_{\text{intragroupes}})} &&\\
\\
t [\text{t de Student}] &: \quad t = \frac{\bar{X}_1 - \bar{X}_2}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}} \quad \sim t(ddl) &&\\
\\
\chi^2 [\text{Test du } \chi^2] &: \quad \chi^2 = \sum \frac{(O_i - E_i)^2}{E_i} \quad \sim \chi^2(ddl) &&\\
\end{align*}

\$\$ Avec $MS$ l'erreur moyenne carrée, $ddl$ le degré de liberté, $\bar{X}_i$ la moyenne du groupe $i$, $s^2_i$ la variance du groupe $i$, $n_i$ le nombre de réplicats du groupe $i$, $O_i$ la distance $\chi^2$ observée, $E_i$ la distance $\chi^2$ attendue.

Ces statistiques suivent des loi de distribution connues, on va donc comparer la statistique observée (calculé sur l'échantillon de données) à la distribution nulle de cette statistique et obtenir ainsi une p-valeur.

Ces staomme La statistique de test pour les tests de permutations dépend du type d'étude et de la relation entre les données (indépendance ou non-indépendance). Pour un test de différence de moyennes entre deux groupes, par exemple, la statistique de test pourrait être définie comme suit :

\[ T = \frac{\bar{X}_1 - \bar{X}_2}{s_{\text{pooled}}} \sqrt{\frac{n_1 n_2}{n_1 + n_2}}, \]

où (\bar{X}\_1) et (\bar{X}*2) sont les moyennes des deux groupes, (s*{\text{pooled}}) est l'écart-type combiné des groupes, et (n_1) et (n_2) sont les tailles des échantillons.

## Mise en œuvre des Tests de Permutations

### Étapes du Test

Les étapes typiques pour mettre en œuvre un test de permutations comprennent :

1.  Formuler les hypothèses nulle et alternative.
2.  Calculer la statistique de test à partir des données observées.
3.  Générer toutes les permutations possibles des données.
4.  Calculer la statistique de test pour chaque permutation.
5.  Comparer la statistique observée à la distribution nulle des statistiques de test.
6.  Conclure sur l'acceptation ou le rejet de l'hypothèse nulle.

## Exemples Pratiques

### Test de Permutations pour la Différence de Moyennes

Considérons un exemple où nous voulons tester si la différence de moyennes entre deux groupes est statistiquement significative. La statistique de test est définie comme dans l'équation ci-dessus.

### Test de Permutations pour la Corrélation

Dans le cas d'une corrélation, la statistique de test pourrait être basée sur la mesure de corrélation de Spearman. Les étapes décrites précedemment devront être suivi également.

# Regressions and Mantel tests

## Regressions

What to do when we have only quantitative variables?
Regression is a method of empirically modeling a response variable (here called $Y$) as a function of one or more explanatory variables ( $X_1, X_2,., X_n$ where $n$ is the number of explanatory variables). Linear regressions are the ones most commonly used in statistics, mainly because they are easy to apply. Let's place ourselves in this linear world. The linear model is classically expressed as follows:

$$ 
Y_i = \alpha + \sum_{j=1}^{n}b_j \times X_{ij} +\epsilon_i\sim\mathcal{N}(0,,\sigma)
$$ {#eq-1}

With $Y_i$ the $i^{th}$ value of the variable $Y$ and $X_{ij}$ the $i^{th}$ value of the $j^{th}$ variable $X$.

When residuals approximate the normal distribution, the parameters $\alpha$ and b are mainly estimate with the least square method.

The parameter b is estimate by :

$$
b_i=\frac{\sum(x_i-\bar{x})(y_i-\bar{y})}{\sum(x_i-\bar{x})}
$$

The parameter $\alpha$ is estimated by :

$$
\alpha=\bar{y}-b_i\bar{x}
$$

### Statistical test on the coefficients.

We got the coefficients! Now we need to make sure that the relationship between the variables is not due to random. In other terms, The way to do that is to verify if the values of the parameters $b$ and $\alpha$ are different from the hypothesis of random. So, we call this hypothesis of a random relationship between the variables the null hypothesis (H0). The permutation test is used to define H0. The idea is to permute the values of $Y_i$ concerning $X_ij$ or vice versa. Here, permutations allow to simulation of random relationships between variables. 

Here is an example of one permutation of the $Y_i$ from the $X_i$.

```{r exemple permutation sepal.width & sepal.length}
library(kableExtra) # Mettre en 1er chunk si nécessaire
library(knitr)
library(dplyr)
library(tidyverse)

data <- iris[1:10,] # sous échantillon de iris

permu <- data.frame("y observed" = data$Sepal.Length,
                    "x observed" = data$Sepal.Width
                    )

samp_ind <- sample(1:nrow(data), nrow(data))

permu[["y permuted"]] <- data$Sepal.Length[samp_ind]
permu[["x permuted"]] <- data$Sepal.Width

permu %>%
  rename("y observed" = y.observed,
         "x observed" = x.observed)%>%
  kable("html", booktabs =TRUE, align = rep("c", 4)) %>%
  add_header_above(c("Observation" = 2, "Permutations" = 2), bold = TRUE)%>%
  kable_paper("hover", full_width = F)
  
```

For each permutation, a linear model is constructed. The set of parameters is estimated from the permuted samples of H0.

```{r}

n_permu <- 1000 # choice of number of permutations

hyp_nulle <- matrix(NA, nrow = n_permu, ncol = 2)
colnames(hyp_nulle) <- c("alpha", "b")

permu <- matrix(NA, ncol = n_permu, nrow = nrow(data))


for (i in 1:n_permu){
# random sampling
samp_ind <- sample(1:nrow(data), nrow(data))

# creation of samples, we permute the Ys with respect to the Xi
permu[,i] <- data$Sepal.Length[samp_ind]


#Coefficients estimation
hyp_nulle[i,1] <- lm(permu[,i]~data$Sepal.Width)$coefficients[[1]]
hyp_nulle[i,2] <- lm(permu[,i]~data$Sepal.Width)$coefficients[[2]]
}

# Distribution of the null hypothesis

par(mfrow = c(1,2))
hist_1 <- hist(hyp_nulle[,1], 
     main = expression("Empirical distribution of "*alpha*" under H0"),
     xlab = expression(""*alpha*"")) 
hist_2 <- hist(hyp_nulle[,2], 
     main = expression("Empirical distribution of b under H0"),
     xlab = "b")



```

### observed regression coefficients

Now we have a good idea of the random effects. We could graphically compare the distributions under H0 with the observations (here the red line) and see if our observed coefficients are under the distribution of H0.

```{r}

# Calcul des coefficients de la regression à partir des données brutes
obs <- lm(data$Sepal.Length~data$Sepal.Width)$coefficients 

# Distribution de H0 et coefficients observés

par(mfrow = c(1,2))
plot(hist_1,
     main = expression("Distribution empirique de "*alpha*" sous H0"),
     xlab = expression(""*alpha*"")) 
abline(v = obs[1], lwd = 2.5, col = "red")

plot(hist_2,
     main = expression("Distribution empirique de b sous H0"),
     xlab = expression("b")) 
abline(v = obs[2], lwd = 2.5, col = "red")



```
The observations seems to be out of H0, we need to make sure using statistics !

## Calculation of test statistics

```{r}

p_a <- length(hyp_nulle[hyp_nulle[,1]<=obs[1]])

p_value_a <- p_a/n_permu

p_b <- length(hyp_nulle[hyp_nulle[,2]>=obs[2]])

p_value_b <- p_b/n_permu

#results representation

df_results <- data.frame(alpha = round(c(obs[1], p_value_a),10),
                         b = round(c(obs[2], p_value_b),4))
row.names(df_results) <- c("coefficient \n observed", "P value")

df_results%>%
  kable("html", booktabs =TRUE, align = rep("c", 3))%>%
  kable_paper("hover", full_width = F)
  
```

The p-value we obtained corresponds to the probability of the observation knowing H. Considering a threshold (mainly 0.05) we can determine the significance of the parameters. If the p-value is under the threshold, the parameter is significant, and vice versa.

Note that you can make permutation tests on all regression coefficients if $Y_i$ and $X_i$ are interchangeable.

## Mantel test

### Uses

The Mantel test (Mantel, 1967) is used to evaluate the relationship between two matrices of correspondences measured on the same individuals. The two correspondence (distances) matrices are denoted by $X$ and $Y$. Here, the null hypothesis describes the independence of the mechanisms governing the distances between individuals. The Mantel test is mainly used for testing correlations between genetics or geographical distances.
The H0 distribution is obtained by permuting the individuals between them. We will use the data set "ozone" from the website UCLA (https://stats.idre.ucla.edu/stat/r/faq/ozone.csv). In this case, Mantel's test is used to know more about correlations between ozone differences and geographical distances between stations. In other terms: Is the ozone variability independent of the geographical variability? 



### Correspondence (distances) matrices.

The first step is to extract the distances matrix of geographical distances and ozone distances between each station. Here, we select the five first individuals of the distances matrix. 
```{r}
library(vegan)

# Download a dataset and create distance matrices
ozone <- read.table("https://stats.idre.ucla.edu/stat/r/faq/ozone.csv", sep=",", header=T)
station.dists <- dist(cbind(ozone$Lon, ozone$Lat))
ozone.dists <- dist(ozone$Av8top)

station.dists <- as.matrix(station.dists)[1:5, 1:5]
ozone.dists <- as.matrix(ozone.dists)[1:5, 1:5]
ozone.dists <- cbind(c("1","2","3","4","5"),as.data.frame(ozone.dists))

names(ozone.dists) <- c("","1","2","3","4","5")
ozone.dists %>% # Visualizing a distance matrix
  kable("html", booktabs =TRUE, align = rep("c", 6))%>%
  kable_minimal()%>%
  column_spec(1, bold = TRUE)

```

The distances matrix should have the same shape as the table x. Now we can apply the Mantel test our to matrix.

### Mantel's test application

There are some packages available to perform the Mantel test. For example, the ade4 package with the "mantel. rtest" function as follows.

```{r}
# Using the ade4 package

library(ade4)
set.seed(seed = 1.5) # Have same results
mantel.rtest(as.dist(station.dists), as.dist(ozone.dists[,-1]), nrepet = 1000)
```
The coefficient of correlation observed is -0.2061116 and the p-value is 0.6793207. If we put the threshold of significance at 0.05. The correlation is not significant here!

Another example of a package is the vegan package which allows to use of different correlation statistics. In our case, we chose the Pearson correlation. 

```{r}
#Using the vegan package, pearson correlation

mantel(xdis = station.dists, ydis = ozone.dists, permutations = 1000)

```
Using this package, the results are similar. well! The p-value is indicated after the term "Significance:" and the correlation coefficient follows the term "Mantel statistic r:". Note that in our case, the number of possible permutations is limited. We should be aware of the length of our data set. 