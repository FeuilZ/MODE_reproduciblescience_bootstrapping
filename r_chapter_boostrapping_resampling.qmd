---
editor: 
  markdown: 
    wrap: 72
---

------------------------------------------------------------------------

title: "Chapter : Bootstrapping and Resampling"

bibliography: references.bib \# Fichier bibliographie execute: freeze:
auto output: html_document: toc: true toc_float: true ---

# General introduction

A dataframe:

```{r}
data <- iris
head(iris)
```

## Confidence interval on a sample

Peut-on estimer la taille moyenne

```{r}

hist(data$Sepal.Width)
shapiro.test(data$Sepal.Width)
qqnorm(data$Sepal.Width)
qqline(data$Sepal.Width)
#Or iris dataset ? 
```

L'Ã©chantillon est normalement distribuÃ©, on peut donc calculer
l'intervalle de confiance de la moyenne de la maniÃ¨re suivante:

```{r}
low <- mean(data$Sepal.Width)-1.96*sd(data$Sepal.Width)/sqrt(length(data$Sepal.Width))
high <- mean(data$Sepal.Width)+1.96*sd(data$Sepal.Width)/sqrt(length(data$Sepal.Width))
print(c(low,high))
```

rq: source INSEE taille moyenne F = 1 m 62, et
https://ourworldindata.org/grapher/average-height-by-year-of-birth?time=latest&country=\~FRA
taille moyenne = 1m6488 pour les gens nÃ©s en 1996 (pas de date aprÃ¨s)
Not in intervall, pop grow, + ech non reprÃ©sentatif de la pop
franÃ§aise

## Confidence interval on multiple sub-samples means

Si on veut dÃ©sormais estimer $\mu$, la taille moyenne des Ã©tudiants
sur les trois promotions du jeu de donnÃ©es.

```{r}
(mu <- mean(data$Sepal.Width))
```

mu correspond Ã  la taille moyenne qu'on veut estimer mais dont on ne
connait pas la vÃ©ritable valeur.

# The Jackknife resampling method

Imaginons mantenant que nous ayons seulement accÃ¨s Ã  un Ã©chantillon
et qu'on veuille estimer la taille moyenne des Ã©tudiants de ces trois
promotions.

```{r}
set.seed(121)
data_sample <- data[sample(1:150,30),]
mean(data_sample$Sepal.Width)
hist(data_sample$Sepal.Width)
shapiro.test(data_sample$Sepal.Width)
qqnorm(data_sample$Sepal.Width)
qqline(data_sample$Sepal.Width)
```

On a seulement accÃ¨s Ã  cet Ã©chantillon non normalement distribuÃ©. La
dessus, nous ne pouvons pas calculer les intervalles de confiance comme
vu prÃ©cedemment. C'est lÃ  que je Jackknife devient intÃ©ressant.

...

## a - Principe

## b - exemple d'implÃ©mentation

test pas du tout fini

```{r}
group <- c()
sampled_data <- c()
for (i in 1:20) { #au total, 100 individus auront Ã©tÃ© Ã©chantillonnÃ©s
  set.seed(i)
  sample_temp <- sample(setdiff(1:139,sampled_data),5)
  sampled_data <- c(sampled_data,sample_temp)
  group <- c(group,mean(data[sample_temp,"Sepal.Width"]))
  
}
```

```{r}
hist(group)
qqnorm(group)
qqline(group)
shapiro.test(group)
```

## c - Avantages et inconvÃ©nients de la mÃ©thode

# Tests de permutation

## Introduction

Les tests de permutations sont une mÃ©thode statistique puissante pour
comparer des groupes et Ã©valuer l'effet d'une variable sur une autre.
Contrairement aux tests paramÃ©triques, les tests de permutations ne
reposent pas sur des hypothÃ¨ses spÃ©cifiques concernant la distribution
des donnÃ©es, les rendant ainsi plus robustes dans certaines situations.
Autrement dit, mÃªme si les donnÃ©es de notre Ã©chantillon ne suive pas
une loi classique (e.g. gaussienne), l'infÃ©rence statistique reste
possible. Ce sont des tests dont le fonctionnement est intuitifs, facile
Ã  mettre en place et leur robustenne les rend particuliÃ¨rement
pratique dans un grand nombre de situations.

## Fondements des Tests de Permutations

### Principe Fondamental

A l'instar des autres tests statistiques classiques (e.g. T de Student,
test du $\chi 2$...), les tests de permutations sont basÃ©s sur une
distribution d'une statistique de test sous l'hypothÃ¨se nulle. La
distribution sous l'hypothÃ¨se nulle correspond Ã  la distribution
thÃ©orique de la statistique du test en supposant que l'effet que nous
testons n'a pas d'impact (i.e. que nos variables explicatives n'ont pas
d'effet sur la variable dÃ©pendante). Dans les tests statistiques
classiques, cette distribution correspond Ã  diffÃ©rentes lois connues,
la plus connue Ã©tant la loi Gaussienne, mais Ã§a peut-Ãªtre la
distribution de Student, la distribution $\chi 2$ etc. La particularitÃ©
des tests de permutations est que l'on va gÃ©nÃ©rer cette distribution
thÃ©orique de faÃ§on empirique directement Ã  partir des donnÃ©es. Les
tests de permutation sont des tests non-paramÃ©triques (ils ne font pas
d'approximation de distribution) et exacts (basÃ©s sur les donnÃ©es
uniquement).

Selon les rÃ¨gles du thÃ©orÃ¨me centrale limite, rÃ©pÃ©ter un grand
nombre de fois une observation d'une variable alÃ©atoire (ici la
statistique de test) mÃ©nera Ã  une distribution Gaussienne dans
laquelle on pourra placer la statistique de test observÃ©e (i.e.
calculÃ©e sur notre Ã©chantillon) et ainsi dÃ©finir la significativitÃ©
de l'effet de nos variables explicatives. En d'autres termes, on
gÃ©nÃ¨re toutes les permutations possibles des observations, calculons
la statistique de test pour chaque permutation, puis comparons la
statistique observÃ©e Ã  cette distribution nulle.

### Statistique de Test

La statistique d'un test est une mesure numÃ©rique utilisÃ©e pour
Ã©valuer si les diffÃ©rences observÃ©es entre les groupes dans une
Ã©tude sont statistiquement significatives. Elle permet de quantifier
l'Ã©cart entre les observations observÃ©es et celles qui pourraient
Ãªtre attribuÃ©es au hasard. Voici quelques exemples de statistiques de
tests connues : \$\$ \begin{align*}
F [\text{ANOVA}] &: \quad F = \frac{MS_{\text{intergroupes}}}{MS_{\text{intragroupes}}} \quad \sim \mathcal{F(ddl_{\text{intergroupes}}, ddl_{\text{intragroupes}})} &&\\
\\
t [\text{t de Student}] &: \quad t = \frac{\bar{X}_1 - \bar{X}_2}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}} \quad \sim t(ddl) &&\\
\\
\chi^2 [\text{Test du } \chi^2] &: \quad \chi^2 = \sum \frac{(O_i - E_i)^2}{E_i} \quad \sim \chi^2(ddl) &&\\
\end{align*}

\$\$ Avec $MS$ l'erreur moyenne carrÃ©e, $ddl$ le degrÃ© de libertÃ©,
$\bar{X}_i$ la moyenne du groupe $i$, $s^2_i$ la variance du groupe $i$,
$n_i$ le nombre de rÃ©plicats du groupe $i$, $O_i$ la distance $\chi^2$
observÃ©e, $E_i$ la distance $\chi^2$ attendue.

Ces statistiques suivent des loi de distribution connues, on va donc
comparer la statistique observÃ©e (calculÃ© sur l'Ã©chantillon de
donnÃ©es) Ã  la distribution nulle de cette statistique et obtenir ainsi
une p-valeur.

Ces staomme La statistique de test pour les tests de permutations
dÃ©pend du type d'Ã©tude et de la relation entre les donnÃ©es
(indÃ©pendance ou non-indÃ©pendance). Pour un test de diffÃ©rence de
moyennes entre deux groupes, par exemple, la statistique de test
pourrait Ãªtre dÃ©finie comme suit :

\[ T = \frac{\bar{X}_1 - \bar{X}_2}{s_{\text{pooled}}}
\sqrt{\frac{n_1 n_2}{n_1 + n_2}}, \]

oÃ¹ (\bar{X}\_1) et (\bar{X}*2) sont les moyennes des deux groupes,
(s*{\text{pooled}}) est l'Ã©cart-type combinÃ© des groupes, et (n_1) et
(n_2) sont les tailles des Ã©chantillons.

## Mise en Å“uvre des Tests de Permutations

### Ã‰tapes du Test

Les Ã©tapes typiques pour mettre en Å“uvre un test de permutations
comprennent :

1.  Formuler les hypothÃ¨ses nulle et alternative.
2.  Calculer la statistique de test Ã  partir des donnÃ©es observÃ©es.
3.  GÃ©nÃ©rer toutes les permutations possibles des donnÃ©es.
4.  Calculer la statistique de test pour chaque permutation.
5.  Comparer la statistique observÃ©e Ã  la distribution nulle des
    statistiques de test.
6.  Conclure sur l'acceptation ou le rejet de l'hypothÃ¨se nulle.

## Exemples Pratiques

### Test de Permutations pour la DiffÃ©rence de Moyennes

ConsidÃ©rons un exemple oÃ¹ nous voulons tester si la diffÃ©rence de
moyennes entre deux groupes est statistiquement significative. La
statistique de test est dÃ©finie comme dans l'Ã©quation ci-dessus.

### Test de Permutations pour la CorrÃ©lation

Dans le cas d'une corrÃ©lation, la statistique de test pourrait Ãªtre
basÃ©e sur la mesure de corrÃ©lation de Spearman. Les Ã©tapes dÃ©crites
prÃ©cedemment devront Ãªtre suivi Ã©galement.

# Régressions et tests de Mantel

## Régressions

La régression est une méthode de modélisation empirique d'une variable
réponse\
(appelée ici $Y$) en fonction d'une ou de plusieurs variables
explicatives (\$ X_1, X_2, ..., X_n  \$ avec \$ n \$ le nombre de
variables explicatives). Ce sont les régressions linéaires qui sont
majoritairement utilisées dans le domaine des statistiques,
principalement pour leur simplicité d'application. Plaçons nous donc
dans ce monde linéaire. Le modèle linéaire est modélisé par :
$$ Y_i = \alpha + \sum_{j=1}^{n}b_j \times X_{ij} + \epsilon_i, \ \ \ \epsilon_i \sim \mathcal{N}(0,\,\sigma) $$
Avec $Y_i$ la $i^{ème}$ valeur de la variable $Y$ et $X_{ij}$ la
$i^{ème}$ valeur de la $j^{ème}$ variable $X$.

### Test statistique sur les coefficients.

Il faut maintenant s'assurer que les paramètres $b$ et $\alpha$ sont
différents de 0. Le test par permutation permet de définir l'hypothèse
nulle (H0 : \$ \alpha = 0\$ et $b = 0$). L'idée est de permuter les
valeurs de $Y_i$ et les $X_i$.

```{r exemple permutation sepal.width & sepal.length}
library(kableExtra) # Mettre en 1er chunk si nécessaire
library(knitr)
library(dplyr)
library(tidyverse)

data <- iris[1:10,] # sous échantillon de iris

permu <- data.frame(echantillon.y = rep(NA, nrow(data)),
                    echantillon.x = rep(NA, nrow(data)))

samp_ind <- sample(1:nrow(data), nrow(data))

permu$echantillon.y <- data$Sepal.Length[samp_ind]
permu$echantillon.x <- data$Sepal.Width

cbind(data[,1:2], permu) %>%
  kable("html", booktabs =TRUE, align = rep("c", 4)) %>%
  add_header_above(c("Sepal" = 2, "echantillon" = 2), bold = TRUE)%>%
  kable_paper("hover", full_width = F)
  
```

Pour chaque permutation, on construit un modèle linéaire. L'ensemble des paramètres estimés à partir des échantillons permutés forment H0.

```{r}

n_permu <- 5000 # choix du nombre de permutations

hyp_nulle <- matrix(NA, nrow = n_permu, ncol = 2)
colnames(hyp_nulle) <- c("alpha", "b")

permu <- matrix(NA, ncol = n_permu, nrow = nrow(data))


for (i in 1:n_permu){
# Tirages aléatoire
samp_ind <- sample(1:nrow(data), nrow(data))

# creation des échantillons, on permute les Y par rapport aux Xi
permu[,i] <- data$Sepal.Length[samp_ind]


#Estimation des coefficients
hyp_nulle[i,1] <- lm(permu[,i]~data$Sepal.Width)$coefficients[[1]]
hyp_nulle[i,2] <- lm(permu[,i]~data$Sepal.Width)$coefficients[[2]]
}

# Distribution de l'hypothèse nulle

par(mfrow = c(1,2))
hist(hyp_nulle[,1], 
     main = expression("Distribution empirique de "*alpha*" sous H0"),
     xlab = expression(""*alpha*"")) 
hist(hyp_nulle[,2], 
     main = expression("Distribution empirique de b sous H0"),
     xlab = "b")

```

