---
title: "Introduction to bayesian modeles for ecology"
author : Coline - Jules - Mathis - Romane - Laura
bibliography: references.bib
execute: 
  freeze: auto
output: 
  html_document:
   toc: true
   toc_float: true
---

```{r setup}
#| include: false

library(tidyverse)
library(ggforce)
library(deSolve)
library(rjags)
library(ggmcmc)
library(sm)



```

# Introduction

-   History of Bayesian concept.
-   Philosophy behind it. Frequentist approach : "What is the probability to observe my data given my model."

Bayesian approach : "What is the probability of m y model given my data."

Rappel : - différence entre loi à posterio jointes et marginales

# General theory behind Bayesian approach.

Explanation in the special case of conjugation between prior and posterior

## Main objective, for context

First, let's take a simple example to explain the idea behind the Bayesian method. We want to estimate the mean abundance per $m^2$ of one fungus in a forest. To do that, we set up some sampling areas in which we count the number of mushrooms. We can simulate the data by taking random observations in a Poisson distribution. Let's suppose that our study has 200 sampling area. **Because it is count data, the number of mushrooms that we will count should follow a Poisson distribution :**

```{r}
n_sample = 200 # sampling area
lbda = 5 # mean of poisson distribution
pois_distr = dpois(1:20, lambda = lbda)
plot(pois_distr,type ="h",
     lwd = 2, col = 'blue',
     xlab = "Mushroom Count", 
     ylab = expression(paste( 'Density or ','[y]')) )

```

To simulate the sampling campaign we are taking values in this Poisson distribution. In our case, those will be used to estimate the mean number of mushrooms in the forest. ($\lambda = 5$ is already known because we simulate the data, but in reality, this is an unknown).

```{r}
set.seed(1000)

Y = rpois(n = n_sample, lambda = lbda)

hist(Y)
```

**So let's pretend that we don't know the** $\lambda$. We want to find the the value of the mean number of mushrooms we will call $\hat{\lambda}$ and we also want to know the probability of this $\hat{\lambda}$. The Bayesian method will give us a range of estimated mean $\hat{\lambda}$ and the probability of those values to be true knowing the observation $Y$. This is what we call the posterior distribution. We can simply write this as follows $[\hat{\lambda} \mid Y]$ which is the probability of $\hat{\lambda}$ knowing our observations. This probability can be found with the equation :

$$
[\hat{\lambda} \mid Y] = [Y \mid \hat{\lambda}  ]\cdot[\hat{\lambda}]
$$

The two components of the right-hand side of the equation are $[Y \mid \hat{\lambda} ]$ the likelihood of our data and $[\hat{\lambda}]$ the prior distribution. First, let's start with the likelihood. Our data follow a Poisson distribution so our likelihood will follow a Poisson distribution :

$$
L(\hat{\lambda} ; y)=[y \mid \hat{\lambda}] = \frac{e^{-\hat{\lambda}} \cdot\hat{\lambda}^{y}}{y!}
$$

This is a first good step, but there is a small issue here, this formula isn't completely usable in this form. This is because it can only take one observation. In English words, it is like asking what is the probability of one observation (one count of mushroom) given a model with a mean $\hat{\lambda}$. This form isn't powerful enough because it uses only one observation. What we want is to use all the data that we have, we want to know the probability of all the observations given a model with a mean $\hat{\lambda}$. To do so we can write the likelihood of all our data $Y$ as the product of the likelihood of each observation $y_i$. (We are allowed to do this only because observations are independent)

$$
\begin{align}
[Y \mid \hat{\lambda}] &= \prod^{n}_{i=1}[y_i \mid \hat{\lambda}] \\
&=\prod^{n}_{i=1}\frac{e^{-\hat{\lambda}} \cdot\hat{\lambda}^{y_i}}{y_i!} \\
&\propto \prod^{n}_{i=1}e^{-\hat{\lambda}} \cdot\hat{\lambda}^{y_i}\\
\end{align}
$$

As you can see we don't keep the $\frac{1}{y_i!}$, it is because we are only interested in the terms that are impacted by $\hat{\lambda}$. The last form which is proportional to the likelihood function has a more convenient form for the next step. Let's rearrange the function in a more convenient form

$$
\begin{align}
\prod^{n}_{i=1}e^{-\hat{\lambda}} \cdot\hat{\lambda}^{y_i}&= e^{-n \cdot\hat{\lambda}} \cdot\hat{\lambda}^{\sum^{n}_{i=1} y_i}\\
&= e^{-n \cdot\hat{\lambda}} \cdot\hat{\lambda}^{n \cdot \bar{y}}\\
\end{align}
$$

The first line just uses the power/exponential multiplication properties. The second line is just a writing simplification that is common in other resources, $mean(y)=\bar{y} = \frac{1}{n}\sum_{i=1}^n \Rightarrow n\cdot \bar{y} = \hat{\lambda}^{\sum^{n}_{i=1} y_i}$.


Now we want to find the prior distribution of $\hat{\lambda}$. First, we have to choose the distribution family of our prior. We will use a Gamma distribution. We are using this one because it lets the prior and the posterior have the same distribution family, it is called conjugate distributions. The prior is called a conjugate prior for the likelihood function. This means that the prior function and the likelihood function have the same form! And this means that we can simplify! let's try it :

$$
\begin{align}
[\hat{\lambda}]&\sim Gamma(\lambda,\alpha_p,\beta_p) \\
&= \lambda^{\alpha_p -1}\frac{\beta_p^\alpha\cdot e^{-\beta_p \lambda}}{\Gamma(\alpha_p)} \propto \lambda^{\alpha_p -1} \cdot e^{-\beta_p \lambda}
\end{align}
$$

Same as the likelihood, we are only interested in the term that varies with $\hat{\lambda}$ so we remove $\frac{\beta^\alpha}{\Gamma(\alpha)}$ and keep the proportional formula of the prior. We can now find the real formula of our posterior distribution.

$$ 
\begin{align}
[\lambda \mid y] &= [y \mid \lambda]\cdot[\lambda] \\
[\lambda \mid y] &\propto e^{-n \cdot\lambda} \cdot\lambda^{n \cdot \bar{y}} \cdot \lambda^{\alpha_p -1} \cdot e^{-\beta_p \lambda}\\
[\lambda \mid y] &\propto e^{-\beta_p \lambda-n\lambda} \cdot\lambda^{n\bar{y}+\alpha_p -1} \\
[\lambda \mid y] &\propto e^{-\lambda (\beta_p +n)} \cdot\lambda^{n\bar{y}+\alpha_p -1}\\
\end{align} 
$$

Does the last formula remind you of something familiar? That's right it is a Gamma distribution! This is the magic of the conjugate distributions. We can now write :

$$
\begin{align}
[\lambda \mid y] &\propto e^{-\lambda \beta} \cdot\lambda^{\alpha -1}\\
[\lambda \mid y] &\sim Gamma(\alpha_p +n\bar{y}, \beta_p +n)
\end{align}
$$

We can do some simulations to show the results. We are looking for the probability of $\hat{\lambda}$, so for the computation we create a vector of all $\hat{\lambda}$ for which we want to know the probability:

```{r}
lambda_hat <- seq(0,10, by = 0.01)
```

And now, in order to compare them, we compute the distribution of the prior and the posterior (which are both following a gamma distribution) with an increasing amount of sample:

```{r}
alph = 1
bet= 1

par(mfrow = c(2,3))
n_obs = 0
for(n_obs in list(0,1:5,1:10,1:50,1:100,1:200)){

  
  # prior distribution
  l_prior = dgamma(lambda_hat, shape = alph, rate = bet)
  
  # posterior distribution
  l_post = dgamma(lambda_hat, shape =  alph + sum(Y[n_obs]), rate = bet + max(n_obs))
  
  plot(lambda_hat,l_prior, ylim = c(0,max(c(l_post,l_prior))),
       type = 'l', lwd = 2, col = 'orange',
       xlab = expression(lambda), 
       ylab = expression(paste('[', lambda, '|y]')) )
  
  lines(lambda_hat,l_post, type = 'l',lty = 3, lwd = 2, col = 'purple')
  abline(v = 5, lty = 2, lwd = 2)
  
  title(paste("n = ",max(n_obs)))

}

```

When we add no data in the computation of the posterior, it is normal that we don't see any modifications from the prior. Adding 5 observation already bring some good information, the prior and the posterior have no longer the same shape and we have a better estimation of the true $\lambda$. Increasing the number of data gives us a better approximation of the true mean. The density of probability is also higher with a lot of data because we have more confidence in the approximation.

# When approximation by computation is needed

In Bayesian statistics, as mentioned earlier, the goal is to update our beliefs about the parameters of a model by combining prior knowledge with the observed information in our collected field data. However, the direct calculation of the posterior distribution can often be challenging to compute analytically, especially in complex models. Resorting to conjugate distribution laws is one solution to overcome the problem, but this is not always feasible. This is where Markov Chain Monte Carlo (MCMC) algorithms come into play to estimate the posterior distributions of parameters.

There are multiple MCMC algorithms (Metropolis-Hastings, Gibbs sampler, Hamiltonian Monte Carlo), each with its own advantages and disadvantages, and the choice of the algorithm depends on the application scenario. However, they all share the same theoretical foundation.

The essential idea of an MCMC algorithm is to create a sequence of dependent random numbers via a Markov chain. When the chain reaches equilibrium (stationary state), it forms a sampling within the posterior distribution, allowing the calculation of quantities of interest such as means, variances, quantiles, and so on.


## Implémentation de l'algorithm de Metropolis-Hastings

Let's implemant the algortihm to try to understand how it works. In the following lines, we will describe the various steps of the Metropolis-Hastings algorithm along with the corresponding R code lines.

**#Step 1 : Definition of the likelihood function and the prior law**

As with the beginning of any Bayesian statistical analysis, we first pose the problem and define the likelihood probability distribution and the prior distributions of the parameters to be estimated.

We define the likelihood as a binomial distribution with parameters $N$ as the total population size and $p$ as the probability of capturing individuals. It is this parameter $p$ that we aim to estimate. We make the assumption that we have no prior information about this parameter, so we choose a non-informative prior:

$$
p \sim \beta(1,1)
$$

```{r}
# [y | p]

likelihood<- function(p, y, N){
  if(p < 0 | p > 1) { 
    return(0)
  } else {
    return(dbinom(x = y, size = N, prob = p))
  }
}

```

```{r}
# [p]
prior.dist = function(p, a.prior = 1, b.prior = 1){
  dbeta(x = p, shape1 = a.prior, shape2 = b.prior)
}
```

**Step 2 : Definition of a candidate position**

We will now aim to move, so we need to define a function to determine a candidate position. Here, we randomly draw this position from a normal distribution with a mean of $p_c$, which is the current position, and we arbitrarily choose a standard deviation value.

```{r}

move  <- function(p, sd.explore = 0.1){
  candidate <- rnorm(1, mean = p, sd = sd.explore)
  return (candidate)
}

```

**Step 3 : Compute of the ratio**

Once we have this candidate position, we need to decide whether to keep it or not. The decision criterion to calculate is the Metropolis-Hastings ratio $r$, which we define as:

$$
r = \dfrac{[p_{t+1} \mid Y]\space \cdot \space [p_{t+1}] \space \cdot \space g(p_{t+1} \mid p_{t})}{[\lambda_{t} \mid Y]\space \cdot \space [p_{t}] \space \cdot \space g(p_{t} \mid p_{t+1})}
$$

where $g(p_{t+1} \mid p_{t})$ is the probability of transitioning from the candidate position to the current position.

```{r}

proba_move <- function(p1, p2, sd.explore = 0.1){
  dnorm(p1, mean = p2, sd = sd.explore)
} 

```

```{r}
MH.ratio <- function(p_c,p, y, N){
  ratio = (likelihood(p_c, y, N) * prior.dist(p) * proba_move(p, p_c))/
    (likelihood(p, y, N) * prior.dist(p) * proba_move(p_c, p))
  
  return(ratio)
}
```

**Step 4 : Decide if we go to the candidate position or not**

To choose if we keep the candidate position $\lambda_{t+1}$ we define $u$ : 

$$
u \sim unif(0,100)
$$

If $u$ is greater than the ratio $r$, we remain at the current position; conversely, if $u$ is less than $r$, we transition to the candidate position.

```{r}
# parameter algorithm
n_iter = 10000
thin = 10

#data 
y = 3
N = 10

#initialization 
p_init = 0.5
p_sample = rep(NA, n_iter)
p_save = rep(NA, n_iter)
p_sample[1] = p_init
i=2


for(i in 2:n_iter){
  p = p_sample[(i-1)]
  p_c = move(p)
    
  ratio = MH.ratio(p_c,p, y, N)
    

  if(runif(1)<ratio){
    p_sample[i] = p_c
  }else{
    p_sample[i] = p
  }
    
  }
p_save = p_sample[seq(1,n_iter, by= thin)]

data = data.frame(iteration = 1:length(p_save),
                    step = p_save)


```


There is a parameter we haven't discussed in this function, and that's $thin$. It means that we will only save the samples within the chain at intervals of 
$thin$. This is due to the fact that the samples are correlated with each other as they depend on the previous position and therefore do not accurately reflect the distribution. Consequently, if we want independent samples, we must discard the majority of samples and keep only one sample every $thin$ steps, with $thin$ being "sufficiently large."

**Step 5 : Visualization**

```{r}
plot(step~iteration, data, "l")

p1 <- ggplot(data = data)+
  geom_histogram(aes(x = step))+
  theme_bw()
p1

alph = 1
bet= 1

```

Both graphs represent the sampling of $p$ in its marginal posterior distribution. This is possible when a sufficient number of iterations is used, allowing the Markov chain to reach a stationary state.

## Discussion with two parameters

And how does it work in multiple dimensions? Obviously, above two parameters to estimate, visualization becomes impossible. So, to keep it visual, we will only perform an example with one additional parameter to estimate.

We will use a simple example: estimating a population mean and standard deviation. We'll define some population-level parameters, collect some data, then use the Metropolis-Hastings algorithm to simulate the joint posterior of the mean and standard deviation.

Let's start by simulating some data.

```{r}

# population level parameters
mu <- 7
sigma <- 3

# collect some data (e.g. a sample of heights)
n <- 50
x <- rnorm(n, mu, sigma)

```
Then, as previously, we define the likelihood and the prior distributions for the parameters to be estimated $\mu$ and $\sigma$:

$$
Y \sim N(\mu,\sigma)
$$
```{r}
# likelihood function
ll <- function(x, muhat, sigmahat){
  sum(dnorm(x, muhat, sigmahat, log = T))
}
```
$$
\mu \sim N(0,100)
$$
$$
\sigma \sim unif(0,10)
$$
```{r}
# prior
pmu <- function(mu){
  dnorm(mu, 0, 100, log = T)
}

psigma <- function(sigma){
  dunif(sigma, 0, 10, log = T)
}

```
In the context of the Metropolis-Hastings algorithm, the focus is typically on probability ratios rather than the probabilities themselves. Logarithms simplify calculations and improve numerical stability in this context, especially for the ratio calculation.

Indeed, as mentioned earlier, we performed:

$$
r_t = \dfrac{[\theta_{t+1} \mid Y]\space \cdot \space [\theta_{t+1}] \space \cdot \space g(\theta_{t+1} \mid \theta_{t})}{[\theta_{t} \mid Y]\space \cdot \space [\theta_{t}] \space \cdot \space g(\theta_{t} \mid \theta_{t+1})}
$$

Which is equal to : 

$$
log(r_t) = [\theta_{t+1} \mid Y]\space \cdot \space [\theta_{t+1}] \space + \space g(\theta_{t+1} \mid \theta_{t}) - [\theta_{t} \mid Y]\space \cdot \space [\theta_{t}] \space + \space g(\theta_{t} \mid \theta_{t+1})
$$


```{r, results='hide'}
# for the compute of the ratio

# poseterior 
post <- function(x, mu, sigma){
  ll(x, mu, sigma) + pmu(mu) + psigma(sigma)
}

# Probabilité de transition multivariée (loi normale)
transition_prob <- function(theta_candidate, theta_current, proposal_sd = 0.1) {
  dnorm(theta_candidate, mean = theta_current, sd = proposal_sd, log = TRUE)
}

# to compute a new candidate 
jump <- function(x, dist = .2){ # must be symmetric
  x + rnorm(1, 0, dist)
}

```

*Algorithm implementation*
```{r}
iter = 10000

theta.post <- data.frame(mu = rep(NA,iter), sigma = rep(NA,iter))

theta.post[1, 1] <- 9
theta.post[1, 2] <- 5

for (t in 2:iter){
  
    # theta_star = proposed next values for parameters
    theta_star <- c(jump(theta.post[t-1, 1],0.1),jump(theta.post[t-1, 2],0.1))
    
    #ratio
    pstar <- post(x, mu = theta_star[1], sigma = theta_star[2])  
    pprev <- post(x, mu = theta.post[t-1, 1], sigma = theta.post[t-1, 2])
    r <- (pstar+transition_prob(c(theta.post[t-1,1],theta.post[t-1,2]), theta_star, 0.1) )-(pprev+transition_prob(theta_star, c(theta.post[t-1,1],theta.post[t-1,2]), 0.1))
    ratio = exp(r[1])
    
    # Acceptation or not 

    if(runif(1)<ratio){
      theta.post[t, ] <- theta_star
    } else {
      theta.post[t, ] <- theta.post[t-1, ]
    }

}

```


**Visualization**

```{r}


xlims <- c(4, 10)
ylims <- c(1, 6)

  par(mfrow=c(1, 2))
  plot(theta.post[ 1:1000,1], theta.post[1:1000,2],
       type="l", xlim=xlims, ylim=ylims, col="blue",
       xlab="mu", ylab="sigma", main="Markov chains")
  text(x=7, y=1.2, paste("Iteration ", 1000), cex=1.5)
  sm.density(x=cbind(c(theta.post[1:1000,1]), c(theta.post[1:1000,2])),
             xlab="mu", ylab="sigma",
             zlab="", zlim=c(0, .7),
             xlim=xlims, ylim=ylims, col="white", 
             verbose=0)
  title("Posterior density")

```

The figure 1 represents the joint sampling of the two parameters. At each iteration, a new pair of parameters is proposed, and the ratio calculation assigns a weight to the proximity of the candidate parameter pair to the prior. Figure 2 represents the joint distribution of the two parameters formed by the sampling. It is from this joint distribution that the marginal posterior distributions of the two parameters arise. Therefore, we can also calculate the statistics (mean, standard deviation, etc.) of interest on these marginal posterior distributions.

# IV) Prior Selection in Ecology

## IV-1) The role of prior knowledge and beliefs

In Bayesian statistics, prior knowledge and beliefs play a central role in the formulation and interpretation of Bayesian models. As explained before, the fundamentals of Bayesian inference lies in combining prior information with observed data to obtain updated or posterior probabilities.

Incorporating existing information to a data set can be based on previous studies, expert opinions, historical data or simply known subjective beliefs. It will allow the future model to avoid over-fitting and favor a more plausible and simple estimation.

## IV-2) Informative and non-informative priors

## IV-3) Incorporating expert opinions and literature data

# V) Case Studies in Bayesian Ecology


## Using JAGS

### two parameter example

For this example we are going to use data taken from a normal law. It is slightly different form the poisson distribution because normal distributions take 2 parameters. So we will need to estimate not only the mean but also the standard deviation will our bayesian approximation. We start by creating the data.

```{r}
Y2 = rnorm(n = 200, mean = 10, sd = 1)
hist(Y2)
```

For this example we will use the software *JAGS* with the library *rjgas*. *JAGS* is a software that let's us build our own model to estimate parameters that we want to find. It need 3 main componente. Fist, the model :

```{r}
mod1 = "
  model{
  ## model 
  for(i in 1:n_obs){# loop when there is multiple data. (will compute the product of the likelihood)
    Y2[i] ~ dnorm(m,preci) # likelihood of our data given parameters
  }
  
  ## Prior distribution
  # All parameters that we want to estimat need a prior distibution
  m ~ dunif(0, 10**3)
  sd ~ dunif(0, 10**3)
  preci <- 1/(sd*sd) # In JAGS dnorm take the precision as input not the standard deviation
  }
"
```

It look like *R* syntax but it is *JAGS* syntax, which is sligthly different for some function

Second, the list of data :

```{r}
data_list1 = list(
  Y2 = Y2,
  n_obs= length(Y2)
  
)
```

This list contain all information needed to make the model run.

Third, the list of initialization :

```{r}
init_list1 <- list(
  m = 5,
  sd = 2
)
```

*JAGS* will probably run MCMC algorithm to find the best parameters, those algorithm need values to start. Try to give values that make sense. If you don't the algorithm might take more time to converge or JAGS could also give error messages.

Now that every thing is setup we can run the model

```{r}
mjags1 <- jags.model(file=textConnection(mod1), 
                     data=data_list1,
                     inits=init_list1, 
                     n.chains = 3) # Number of MCMC 
```

```{r}
# function to extract mcmc 
postSamples1 <- coda.samples(mjags1, 
                             variable.names = c("m","sd"),
                             n.iter = 10000, 
                             thin = 10)

postSamples_df1 <-  postSamples1 %>% ggs()
```

Always verify if the markov chain are stationary (otherwise you will have a bad estimation of the posterior distribution)

```{r}
postSamples_df1%>%
  ggplot() +
  facet_wrap(~Parameter, scales = "free")+
  geom_line(aes(Iteration, value , col = as.factor(Chain)), alpha = 0.3)+
```

All MCMC seem to be stationary, we can go on.

```{r}
scale_color_manual(values = wesanderson::wes_palette("FantasticFox1", n = 5))          
postSamples_df1 %>%
  ggplot() +
  facet_wrap(~as.factor(Chain)*Parameter, scales = "free") +
  geom_histogram(data = postSamples_df1, aes(x= value, y =..density.., fill = as.factor(Chain)),
                 position = "identity", alpha = 0.7)+
  scale_fill_manual(values = wesanderson::wes_palette("FantasticFox1", n = 5))

str(postSamples_df1$value)
# postSamples_df1 %>%
#   pivot_wider(id_cols = -c(Iteration, Chain), names_from = "Parameter", values_from = "value")%>%
#   ggplot() +
#   facet_wrap(~as.factor(Chain), scales = "free") +
#   geom_point(data = postSamples_df1, aes(x= m, y =sd),
#                  position = "identity", alpha = 0.7)

```

Here we look at the posterior distribution estimated by the 3 chain for the mean and the standard error.

For this example we are going to use data taken from a normal law. And we can for example suppose that we want to study the length of snakes in 5 different dessert (that we gonna call A,B,C,D,E for simplicity).

```{r}

set.seed(1000)
y_means = round(runif(n= 5, min = 5, max = 15))
n_obs = 40
Y3 = c()
class = c()
IDclass = c()
ID = c("A","B","C","D","E")
for(i in 1:length(y_means)){
 Y3= c(Y3, rnorm(n = n_obs, mean = y_means[i], sd = 2))
 class = c(class,rep(ID[i],n_obs))
 IDclass = c(IDclass,rep(i,n_obs))
}
data = data.frame(Y3, class, IDclass)

ggplot(data)+
  geom_sina(aes(class,Y3))

```

```{r}
mod2 = "
  model{
  ## model 
  for(i in 1:n_obs){
    Y3[i] ~ dnorm(m[IDclass[i]],preci)
  }
  
  ## Prior distribution
  for(n in 1:n_class){
    m[n] ~ dunif(0, 10**3)
  }
  sd ~ dunif(0, 10**3)
  preci <- 1/(sd*sd)
  }
"
```

For this time we want to estimate 5 different means and we will suppose that standard deviation is the same between each class (but we could also estimate it with respect to the class). To estimate multiple parameter we initiate as much prior as there is class with the loop `for(n in 1:n_class){ m[n] ~ dunif(0, 10**3)}`

```{r}
data_list2 = list(
  Y3 = data$Y3, # data vector
  n_obs= length(data$Y3), # number of observations
  IDclass = data$IDclass, # vector to specify class of each observation
  n_class = max(data$IDclass) # Number of class
)
```
For this example we add `IDclass = data$IDclass` and ` n_class = max(data$IDclass)` for the class specification in the model.

```{r}
init_list2 <- list(
  m = rep(5,5), 
  sd = 2
)
```

This is where we initiate the prior, the only change is that we initialize 5 mean with `m = rep(5,5)`

We run the model :
```{r}
mjags2 <- jags.model(file=textConnection(mod2), 
                     data=data_list2,
                     inits=init_list2, 
                     n.chains = 3)

postSamples2 <- coda.samples(mjags2, 
                             variable.names = c("m","sd"),
                             n.iter = 10000, 
                             thin = 10)
```

Some data manipulation for the visualization
```{r}
postSamples_df2 <-  postSamples2 %>% ggs()
params_names = unique(postSamples_df2$Parameter)
postSamples_df2$true_values = NA
for( i in 1:6){
  temp = which(postSamples_df2$Parameter == params_names[i])
  if(substr(params_names[i],1,1) == "m"){
      postSamples_df2$true_values[temp] = y_means[i]
  }else{
    postSamples_df2$true_values[temp] = 2
  }

}
```

Check if the chains are stationary.
```{r}
postSamples_df2%>%
  ggplot() +
  facet_wrap(~Parameter, scales = "free")+
  geom_line(aes(Iteration, value , col = as.factor(Chain)), alpha = 0.3)+
  scale_color_manual(values = wesanderson::wes_palette("FantasticFox1", n = 5)) 
```

Finally we look at the results of posterior distribution of the estimated means and the estimated standard deviation.
```{r}
         
postSamples_df2 %>%
  ggplot() +
  facet_wrap(~Parameter, scales = "free") +
  geom_histogram(aes(x= value, y =after_stat(density), fill = as.factor(Chain), col = as.factor(Chain)),
                 position = "identity", alpha = 0.3)+
  geom_histogram(aes(x= value, y =after_stat(density), col = as.factor(Chain)),
                 position = "identity", alpha = 0)+
  scale_fill_manual(values = wesanderson::wes_palette("FantasticFox1", n = 5))+
  scale_color_manual(values = wesanderson::wes_palette("FantasticFox1", n = 5))+
  geom_vline(aes(xintercept = true_values), alpha = 0.7, linetype = "dashed")

# str(postSamples_df1$value)
# postSamples_df1 %>%
#   pivot_wider(id_cols = -c(Iteration, Chain), names_from = "Parameter", values_from = "value")%>%
#   ggplot() +
#   facet_wrap(~as.factor(Chain), scales = "free") +
#   geom_point(data = postSamples_df1, aes(x= m, y =sd),
#                  position = "identity", alpha = 0.7)

```

## V-1) Highlighting specific ecological studies that employed Bayesian methods

## V-2) Illustrative examples from different ecological sub-disciplines
