[
  {
    "objectID": "Mixed_models.html",
    "href": "Mixed_models.html",
    "title": "Mixed models in ecology",
    "section": "",
    "text": "library(nlme)\nlibrary(ggplot2)\nlibrary(gridExtra)\nlibrary(predictmeans)\n\nLe chargement a nécessité le package : lme4\n\n\nLe chargement a nécessité le package : Matrix\n\n\n\nAttachement du package : 'lme4'\n\n\nL'objet suivant est masqué depuis 'package:nlme':\n\n    lmList\n\n\nLe chargement a nécessité le package : lmerTest\n\n\n\nAttachement du package : 'lmerTest'\n\n\nL'objet suivant est masqué depuis 'package:lme4':\n\n    lmer\n\n\nL'objet suivant est masqué depuis 'package:stats':\n\n    step\n\nlibrary(sp)\n\nThe legacy packages maptools, rgdal, and rgeos, underpinning the sp package,\nwhich was just loaded, will retire in October 2023.\nPlease refer to R-spatial evolution reports for details, especially\nhttps://r-spatial.org/r/2023/05/15/evolution4.html.\nIt may be desirable to make the sf package available;\npackage maintainers should consider adding sf to Suggests:.\nThe sp package is now running under evolution status 2\n     (status 2 uses the sf package in place of rgdal)\nMise en forme ::: {style=“text-align: justify”} Teste :::"
  },
  {
    "objectID": "Mixed_models.html#introduction",
    "href": "Mixed_models.html#introduction",
    "title": "Mixed models in ecology",
    "section": "Introduction",
    "text": "Introduction\nGeneral Linear Models, such as linear regressions, ANOVA, and ANCOVA, are commonly employed to depict the relationships between a dependent variable, denoted as (Y), and one or more independent variables (\\(X_1, X_2, ..., X_n\\)). These models are based on several assumptions, including homoscedasticity of the variance, non-collinearity of residuals, and normality of residuals. Generalized Linear Models (GLMs) can address homoscedasticity and normality assumptions by accommodating data from different distributions like Poisson, binomial, or Gamma distributions, which are often encountered in ecology. However, it is crucial to validate the non-collinearity of residuals.\nIn biological and ecological experiments, the assumption of independence of measurements, necessary for non-collinearity of residuals, is frequently violated. This is because measurements are often correlated within families, regions, repeated on the same individuals, or across time and sites. In such cases, it becomes necessary to employ mixed models. These models, extensions of both general and generalized linear models, consider the correlation of measurements by introducing individuals, regions, families, or other factors as random effects in the models. This incorporation allows for a more accurate representation of the complex dependencies present in the data.\nWhat is a random effect, and how do I determine if my effect is random or fixed ?\nTo clarify the distinction between fixed and random effects, let’s examine two examples:\n\nExample 1: Comparing individual cars\nAbdel, Antonio, Odeline, and Aela want to compare the oil consumption of their individual cars. They conduct a test by measuring oil consumption during a 30-kilometer drive, repeated five times in a day, with consistent traffic conditions and driving patterns. The data set consists of one factor with four levels (representing the four cars) and five replicates each. Performing a one-way ANOVA allows them to determine which car is the most economical. In this scenario, the factor “car” is fixed, and the analysis provides conclusions specific to the four studied cars.\nExample 2: Assessing homogeneity within a car model\nA car constructor aims to evaluate the homogeneity of oil consumption within a car model, treating the model as a population of cars with expected heterogeneity in gas consumption. Similar to Example 1, they measure oil consumption by driving each car 30 kilometers, five times in a day, resulting in a data set with one factor and four levels, each with five replicates. Unlike the first example, the cars in this case were sampled from a larger population, and the objective is to draw conclusions about the entire population, not just the sampled cars. Here, a mixed model with the factor ‘car’ as a random factor should be used.\n\nIn summary, a factor is designated as fixed when the experimenter intentionally chooses a limited number of levels for investigation, aiming to assess the impact of each level on the response variable. A factor is considered random when the selected levels represent only a sample from all possible levels. In this case, the objective is to understand the variability in the response variable attributed to this factor.\nFor example, let’s consider a researcher investigating the influence of the number of training sessions per week on the concentration of red blood cells in recreational athletes. The researcher collects data from 50 athletes in a local club who train between 1 and 5 times a week. Initially planning a simple ANOVA with the number of training sessions as the main factor, the researcher discovers that most athletes in the data set belong to only 10 families, leading to non-independent measurements. To address this issue, the researcher opts for a mixed model, treating the number of training sessions as a fixed factor and the family as a random factor. This approach allows the exploration of variability between families without the intention of directly comparing them.\nNow that we have a general understanding of what mixed models are, we can delve into the mathematical formalism of these models. In this chapter, you will discover how matrices can be employed to create mixed models, explore the various dependency structures that exist, and ultimately, find an implementation of mixed models in R."
  },
  {
    "objectID": "Mixed_models.html#formalization-of-the-linear-mixed-model",
    "href": "Mixed_models.html#formalization-of-the-linear-mixed-model",
    "title": "Mixed models in ecology",
    "section": "1. Formalization of the linear mixed model",
    "text": "1. Formalization of the linear mixed model\nThe linear mixed model can be formulated as follows:\n\\[\nY_{i} = \\beta X_{i} + \\gamma_i Z_{i} + \\varepsilon_{i}\n\\]\nwhere:\n\n\\(Y_i = n_i \\times 1\\) measurements for subject \\(i\\)\n\\(X_i = n_i \\times p\\) matrix of vectors for fixed effects\n\\(\\beta_i= p \\times 1\\) parameters for fixed effects\n\\(Z_i = n_i \\times p\\) matrix of vectors for random effects\n\\(\\gamma_i = r \\times 1\\) parameters for random effects\n\\(\\varepsilon_i = n_i \\times 1\\) residuals for individual \\(i\\)\n\nA mixed effects model incorporates random effects (\\(\\gamma_i\\)), or a combination of both random and fixed effects (\\(\\beta\\)), whereas a standard linear model includes only fixed effects.\nWhen it is clear that the researcher intends to compare particular, predefined levels of a treatment, those levels are considered fixed effects. Conversely, when the levels of the treatment are drawn from a larger population of possible levels, the treatment is treated as a random effect.\nIn addition, random effects are included in a model when there is a correlation or dependence among the observations that cannot be ignored.\nRANDOM VARIABLE = « something that could not be known before sampling/measurement/observation”.\n\n\\(beta_i= p \\times 1\\) parameters for fixed effects\n\\(Z_i = n_i \\times p\\) matrix of vectors for random effects\n\\(gamma_i = r \\times 1\\) parameters for random effects\n\\(varepsilon_i = n_i \\times 1\\) residuals for individual \\(i\\)\n\nIn matrix form, the mixed model is written as:\n\\[\nY \\sim \\mathcal{N{n}}(X\\theta, \\Sigma)\n\\] where:\n\\(Y\\) is the response vector of the observations, \\(X\\theta\\) is the expectation of the response vector \\(Y\\) and \\(\\Sigma\\) is the variance matrix."
  },
  {
    "objectID": "Mixed_models.html#matrix-computation-in-mixed-models",
    "href": "Mixed_models.html#matrix-computation-in-mixed-models",
    "title": "Mixed models in ecology",
    "section": "2. Matrix computation in mixed models",
    "text": "2. Matrix computation in mixed models\nWe can note that if the response vector \\(Y\\) is of dimension \\(n\\), the matrix \\(\\Sigma\\) is of dimensions \\(n \\times n\\). Since \\(\\Sigma\\) is symmetric, it comprises \\(n(n + 1)/2\\) parameters. This is because, in a symmetric matrix, the elements above (or below) the main diagonal are the same as those below (or above), reducing the total number of parameters needed to describe the matrix.\nHowever, the limitation of the available data prevents considering models where all these \\(n(n + 1)/2\\) parameters are free. This restriction arises from the need to have a significant amount of data to reliably estimate each parameter, which quickly becomes unrealistic with a limited dataset.\nTo address this issue, the linear mixed-effects model proposes an approach where a structure is imposed on the variance matrix \\(\\Sigma\\). This structure, governed by a limited number of parameters called “variance parameters,” denoted \\(\\psi\\), reduces the number of parameters needed to describe the covariance matrix. Consequently, the model can be realistically adapted even with a limited amount of data, while accounting for the correlation between observations within the framework of linear mixed-effects models. The model parameters include \\(\\theta\\) for the expectation and \\(\\psi\\) for the variance.\n$$ M_{2} = ( {\n\\[\\begin{array}{cc}\n    A & B \\\\\n    C & D \\\\\n  \\end{array}\\]\n} )\n$$ Il est possible de rencontrer des modèles linéaires (mixtes) sous forme matricielle, de part la concision de la forme. Il est donc naturel de présenter cette forme dans le cadre des modèles mixtes.\nPour rappel, un modèle linéaire, de type regression linéaire, avec \\(p\\) variables explicatives peut s’écrire sous la forme \\[y_i = \\beta_0 + \\beta_1x_i^{(1)} + \\ldots + \\beta_px_i^{(p)} + \\varepsilon_i\\], où \\(y_i\\) représente une observation de la variable réponse \\(Y\\) pour l’individu \\(i\\), \\(\\beta_0\\) l’ordonnée à l’origine, \\(\\beta_1,...,\\beta_p\\) les coefficients associés à chaque variables explicatives \\(X_1,...,X_p\\), \\(x_i^{(1)},...,x_i^{(p)}\\) p observations (pour les p variables explicatives) pour l’individu \\(i\\), et \\(e_i\\) un terme d’erreur associé à cet individu \\(i\\). On peut voir \\(e_i\\) comme une réalisation d’une variable aléatoire \\(E_i\\) distribuée selon une loi normale \\(\\mathcal{N}(0,\\sigma^2)\\). En notant \\[y=\\begin{pmatrix}\ny_1\\\\\n\\vdots\\\\\ny_n\\\\\n\\end{pmatrix}\\], \\[X=\\begin{pmatrix}\n1&x_1^{(1)} & \\ldots & x_1^{(p)}\\\\\n\\vdots & \\vdots & \\ldots & \\vdots \\\\\n1 & x_n^{(1)} & \\ldots & x_n^{(p)}\n\\end{pmatrix}\\], \\[\\theta=\\begin{pmatrix}\n\\beta_0\\\\\n\\vdots\\\\\n\\beta_p\\\\\n\\end{pmatrix}\\] et $$e=\n\\[\\begin{pmatrix}\n\\varepsilon_0\\\\\n\\vdots\\\\\n\\varepsilon_n\\\\\n\n\\end{pmatrix}\\]\n\\[, on peut réécrire le modèle précédent sous la forme \\]y=X+e$$. Ici, \\(e\\) est un vecteur de n réalisations indépendantes d’une variable aléatoire \\(E_i\\) suivant une loi noramle \\(\\mathcal{N}(0,\\sigma^2)\\). Ainsi, \\(e\\) est lui même une réalisation d’une variable aléatoire \\(E\\) de distribution \\(\\mathcal{N}_n(0,\\sigma^2I_n)\\) (\\(e_i\\) est une observation de la variable aléatoire \\(E_i\\) distribuée selon une loi normale \\(\\mathcal{N}(0,\\sigma^2)\\)). De la même manière, \\(y\\) est une observation de \\(Y=X\\theta+E\\) où \\(Y\\sim\\mathcal{N}_n(X\\theta,\\sigma^2I_n)\\) (\\(y_i\\) est l’observation de \\(Y_i\\) distribuée selon une loi normale \\(\\mathcal{N}((X\\theta)_i,\\sigma^2)\\)). Ainsi, en introduisant \\(Y\\) et \\(E\\), le modèle précédent peut s’écrire \\(Y=X\\theta+E\\) où \\(\\mathrm{E}\\stackrel{iid}\\sim\\mathcal{N}_n(0,\\sigma^2I_n)\\).\nPar définition, la réponse moyenne est de \\(X\\theta\\), plus ou moins un terme d’erreur qui en moyenne vaut 0 mais qui varie de \\(\\sigma^2I_n\\). Ainsi, on peut écrire \\(Y\\sim\\mathcal{N}_n(X\\theta,\\sigma^2I_n)\\). On remarque qu’en écrivant \\(\\mathrm{E}\\stackrel{iid}\\sim\\mathcal{N}_n(0,\\sigma^2I_n)\\), toutes les erreurs ont la même variance (\\(\\sigma^2\\)) et deux individus (statistiques) car tous les échantillons sont indépendants. On verra par la suite que si cette condition d’indépendance n’est pas respectée, toutes les erreurs n’ont pas la même variance, on parle de structure de dépendance. La dépendance entre les mesures détermine la structure de dépendance (mesures répétées dans le temps, individus groupés par une ascendance commune,…)."
  },
  {
    "objectID": "Mixed_models.html#dependency-structures",
    "href": "Mixed_models.html#dependency-structures",
    "title": "Mixed models in ecology",
    "section": "3. Dependency structures",
    "text": "3. Dependency structures\n\n3.1 Case of repeated measurements\n\n\nRepeted measurements in time\nWe want to evaluate the effect of different diet on weight gain in rats. Several animals (\\(j\\)) follow each diet (\\(i\\)), and they kept the same diet accross all the experiment. Each week animal weight (\\(Y_{ij}\\)) is measured, during T weeks. In this case, measures are repeated accross time, such measurements are called longitudinal data. To analyse this data, the temporal dependency must be taken into account, for this, the following model can be used:\n\\[E(Y_{ijt}) = µ + α_i + γ_t + (αγ)_{it}\\]\nwith\n\\[Cov(Y_{ijt}, Y_{i'j't'}) = \\left\\{\n  \\begin{array}{ll}\n  σ^2ρ \\ \\ si \\ \\ (i, j) = (i', j') \\\\\n     0 \\ sinon \\\n   \\end{array}\n  \\right.\\]\nIn this model, the covariance between two measurements made at times t and t’ on the same model is constant, whatever the time interval between the two measurements.\nModel A model is proposed here which takes into account the kinetic aspect of the experiment and predicts that the dependence between two measurements depends on the time interval between them. Such a dependency cannot be represented simply as a random effect.\nDependency structure We assume that all measurements have the same variance\n\\[ V(Y_{ijt} =  σ^2) \\]\nand the covariance between them is\n\\[Cov(Y_{ijt}, Y_{i'j't'}) = \\left\\{\n  \\begin{array}{ll}\n  σ^2ρ^{|t-t'|} \\ \\ si \\ \\ (i, j) = (i', j') \\\\\n     0 \\ sinon \\\n   \\end{array}\n  \\right.\\]\nThis structure assumes that measurements made on different animals are independent. It is also assumed that |ρ| &lt; 1, which implies that the longer the time interval, the less correlated the tests on the same animal. This form of covariance corresponds to an autoregressive process of order 1, generally denoted AR(1). This model has two variance parameters: the temporal correlation ρ and the variance of each observation \\(σ^2\\).\n\\[\n  ψ = \\left( {\\begin{array}{cc}\n    ρ \\\\\n    σ^2 \\\\\n  \\end{array} } \\right)\n\\]\nBecause of the independence between the measurements obtained on different animals, the variance matrix Σ also has the same diagonal block shape, but the block (R) differs.\n\\[  \nR = \\left( {\\begin{array}{cc}\n     σ^2 & σ^2ρ & σ^2ρ^2 & ... & σ^2ρ^{T-1}\\\\\n     σ^2ρ & ... & ... & ... & ...\\\\\n     σ^2ρ^2 & ... & σ^2 & ... & σ^2ρ^2\\\\\n     ... & ... & ... & ... & σ^2ρ\\\\\n    σ^2ρ^{T-1} & ... & σ^2ρ^2 & σ^2ρ & σ^2\\\\\n  \\end{array} } \\right)\n\\]\nWe are going to use the BodyWeight dataset from the nlme package. In this dataset, weight is measured on 16 rats every 7 days during 64 days (which gives 11 measurements for each rats). Three diets are tested with 88 rats following diet 1 and 44 following diet 2 and 3.\nThe reasearch question is: Is weight gain different depending on the diet? The model will be a mixed model with diet and time as fixed factor and individuals as random factor: weight ~ Diet * Time | Rat.\n\nhead(BodyWeight, 10)\n\nGrouped Data: weight ~ Time | Rat\n   weight Time Rat Diet\n1     240    1   1    1\n2     250    8   1    1\n3     255   15   1    1\n4     260   22   1    1\n5     262   29   1    1\n6     258   36   1    1\n7     266   43   1    1\n8     266   44   1    1\n9     265   50   1    1\n10    272   57   1    1\n\n\n\ntime_model = gls(weight ~ Diet * Time, data = BodyWeight,correlation = corAR1(form = ~1 | Rat))\nsummary(time_model)\n\nGeneralized least squares fit by REML\n  Model: weight ~ Diet * Time \n  Data: BodyWeight \n       AIC      BIC    logLik\n  1152.248 1177.334 -568.1239\n\nCorrelation Structure: AR(1)\n Formula: ~1 | Rat \n Parameter estimate(s):\n      Phi \n0.9895746 \n\nCoefficients:\n                Value Std.Error   t-value p-value\n(Intercept) 250.11069 13.327526 18.766475  0.0000\nDiet2       203.46561 23.083952  8.814158  0.0000\nDiet3       260.91151 23.083952 11.302723  0.0000\nTime          0.37351  0.090964  4.106160  0.0001\nDiet2:Time    0.62384  0.157554  3.959506  0.0001\nDiet3:Time    0.18780  0.157554  1.191998  0.2349\n\n Correlation: \n           (Intr) Diet2  Diet3  Time   Dt2:Tm\nDiet2      -0.577                            \nDiet3      -0.577  0.333                     \nTime       -0.222  0.128  0.128              \nDiet2:Time  0.128 -0.222 -0.074 -0.577       \nDiet3:Time  0.128 -0.074 -0.222 -0.577  0.333\n\nStandardized residuals:\n        Min          Q1         Med          Q3         Max \n-1.44446363 -0.63038331  0.02804647  0.25238087  2.93319234 \n\nResidual standard error: 37.70413 \nDegrees of freedom: 176 total; 170 residual\n\n\ninterpretation des results\n\n\n3.2 Case of spatial autocorrelation\nDependency structure We want to take into account the dependency due to the possible spatial proximity between the sites at which the measurements were taken.\nTo do this, d(i, i’) is the distance separating sites i and i’, and the following equation is used\n\\[Cov(Y_i, Y_i{'}) = e^{−δ.d(i,i')}\\]\nAs in the case of repeated measurements, there is no simple way of writing this in terms of random effects. Moreover, since all the measurements are dependent, the matrix Σ is no longer diagonal per block and is written as :\n\\[\n  Σ = \\left( {\\begin{array}{cc}\n     σ^2 + γ^2 & e^{−δ.d(i,i')}& ...& e^{−δ.d(i,i')}\\\\\n     e^{−δ.d(i,i')}& σ^2 + γ^2 & e^{−δ.d(i,i')} & \\vdots\\\\\n     \\vdots & e^{−δ.d(i,i')}  & σ^2 + γ^2 & e^{−δ.d(i,i')}\\\\\ne^{−δ.d(i,i')}& \\ldots & e^{−δ.d(i,i')} & σ^2 + γ^2\\\\\n  \\end{array} } \\right)\n\\]\n\ndata.spatialCor.glsExp &lt;- gls(y ~ x, data = data.spatialCor,\n    correlation = corExp(form = ~LAT + LONG, nugget = TRUE),\n    method = \"REML\")\n\n\nsummary(data.spatialCor.glsExp)\n\nGeneralized least squares fit by REML\n  Model: y ~ x \n  Data: data.spatialCor \n       AIC      BIC    logLik\n  974.3235 987.2484 -482.1618\n\nCorrelation Structure: Exponential spatial correlation\n Formula: ~LAT + LONG \n Parameter estimate(s):\n    range    nugget \n1.6956723 0.1280655 \n\nCoefficients:\n               Value Std.Error  t-value p-value\n(Intercept) 65.90018 21.824752 3.019516  0.0032\nx            0.94572  0.286245 3.303886  0.0013\n\n Correlation: \n  (Intr)\nx -0.418\n\nStandardized residuals:\n       Min         Q1        Med         Q3        Max \n-1.6019483 -0.3507695  0.1608776  0.6451751  2.1331505 \n\nResidual standard error: 47.68716 \nDegrees of freedom: 100 total; 98 residual\n\n\nIn spatially correlated data, variance increases with increasing distance up to a point the sill. The span of distances over which points are correlated is called the range.\nWhile we might expect the value of variance at a distance of zero to be zero, in reality we rarely have sampling units that approach such a small distance from one another. The value of variance when distance is equal to zero is the nugget. Typically this is the result of unexpected variability in your data that spatial patterns alone cannot account for.\nHere, in our example, the value of the sill, the range and the nugget are respectively 47.68, 1.69 and 0.12."
  },
  {
    "objectID": "Mixed_models.html#application",
    "href": "Mixed_models.html#application",
    "title": "Mixed models in ecology",
    "section": "4. Application",
    "text": "4. Application\nFor this example of a mixed model application, we will use a general linear mixed model. This is a special case of a general linear model, in which the response is quantitative and the predictor variables are both quantitative and qualitative, and the model includes random factors to take account of data dependency. Mixed models must respect the normality of residuals and the homogeneity of variances."
  },
  {
    "objectID": "Mixed_models.html#dataset-presentation-and-objectives-of-the-analysis",
    "href": "Mixed_models.html#dataset-presentation-and-objectives-of-the-analysis",
    "title": "Mixed models in ecology",
    "section": "DATASET PRESENTATION AND OBJECTIVES OF THE ANALYSIS",
    "text": "DATASET PRESENTATION AND OBJECTIVES OF THE ANALYSIS\nFor this work exercise, we will use data from a study performed on penguins. This study aims to test whether species, sex,work and island influence the body mass of penguins. In the experimental design, the data are collected from one year to the next (from 2007 to 2009), which suggests that the penguin body mass data are dependent on each other from one year to the next. This dependency will be included in the model. The data contains:\n- species: three species of penguins (Chinstrap, Adelie, or Gentoo), categorical variable\n- island: island name (Dream, Torgersen, or Biscoe) in the Palmer Archipelago (Antarctica), categorical variable\n- sex: penguin sex (female, or male), categorical variable\n- year: years of data collection (2007, 2008, or 2009), continuous variable\n- body_mass_g: body mass of the penguins (in grams), continuous variable\n\nThe response variable is ‘body_mass_g’, while ‘species’, ‘island’, and ‘sex’ are assumed predictors. To include data dependency, ‘year’ will be included as a random factor in the model. The underlying question for this research is: do the species, island and sex drive the body mass of penguins?\n\n4.1 Data import\n\n# Data import\ndf &lt;- read.table(\"https://gist.githubusercontent.com/slopp/ce3b90b9168f2f921784de84fa445651/raw/4ecf3041f0ed4913e7c230758733948bc561f434/penguins.csv\", sep = \",\" , header = TRUE)\n# Make sure that our variables 'species', 'island' and 'sex' are all factors in the choice.\ndf$species=as.factor(df$species)\ndf$island=as.factor(df$island)\ndf$sex=as.factor(df$sex)\n\n# Check for missing values\ncolSums(is.na(df))\n\n            rowid           species            island    bill_length_mm \n                0                 0                 0                 2 \n    bill_depth_mm flipper_length_mm       body_mass_g               sex \n                2                 2                 2                11 \n             year \n                0 \n\n\nWe can see that there are some missing values, including 2 for the response variable \\(Y\\) ‘body_mass_g’ and 11 for the explanatory variable \\(X\\) ‘sex’. We’re going to delete the rows with the missing values.\n\n# Rows with missing values are marked.\nwhich(is.na(df$body_mass_g), arr.ind=TRUE)\n\n[1]   4 272\n\nwhich(is.na(df$sex), arr.ind=TRUE)\n\n [1]   4   9  10  11  12  48 179 219 257 269 272\n\n# We delete the rows 4, 9, 10, 11, 12, 48, 179, 219, 257, 269, and 272.\ndf=df[-c(4,9,10,11,12,48,179,219,257,269,272), ]\n\n# Check for missing values\ncolSums(is.na(df))\n\n            rowid           species            island    bill_length_mm \n                0                 0                 0                 0 \n    bill_depth_mm flipper_length_mm       body_mass_g               sex \n                0                 0                 0                 0 \n             year \n                0 \n\n# Ok\n\n\n\n4.2 Data exploration\nBefore any statistical analysis, it is ESSENTIAL to explore the data in order to avoid any errors. Here is the list of explorations to be carried out before modelling:\n\nCheck for outliers in \\(Y\\) and the distribution of \\(Y\\) values.\nIf \\(X\\) is an independent quantitative variable, check for the presence of outliers in X and the distribution of the values of X. 2b. If \\(X\\) is a qualitative independent variable, analyse the number of levels and the number of individuals per level.\nAnalyse the potential relationships between \\(Y\\) and the \\(X_{s}\\).\nCheck for the presence of interactions between \\(X_{s}\\).\nCheck for collinearity between \\(X_{s}\\).\n\n\n4.2.1 Outliers in \\(Y\\) and \\(Y\\) distribution\n\npar(mfrow=c(2,2))\n# Boxplot\nboxplot(df$body_mass_g,col='blue',ylab='Masse corporel')\n# Cleveland plot\ndotchart(df$body_mass_g,pch=16,col='blue',xlab='Masse corporel')\n# Histogram\nhist(df$body_mass_g,col='blue',xlab=\"Masse corporel\",main=\"\")\n# Quantile-Quantile plot\nqqnorm(df$body_mass_g,pch=16,col='blue',xlab='')\nqqline(df$body_mass_g,col='red')\n\n\n\n\nHere, the Boxplot and Cleveland Plot show no individuals with outliers. The Cleveland Plot shows us that there appears to be a group of individuals with a body mass between 5000 and 6000g, while the rest is between 3000 and 4000g. The Histogram and the QQ Plot show that \\(Y\\) hardly follows a Normal distribution. It is not a major issue, as the validity of the model is based on the normality of the residuals, which we will be demonstrated later.\n\n\n4.2.2 Outliers in \\(Xs\\)\n\nFor \\(X_s\\) which are quantitative: check for outliers and distribution\n\nNo quantitative predictor here.\n\nFor categorical \\(Xs\\): number of levels and number of individuals per level.\n\n\n# Factor Species\nsummary(df$species)\n\n   Adelie Chinstrap    Gentoo \n      146        68       119 \n\n# Factor Island\nsummary(df$island)\n\n   Biscoe     Dream Torgersen \n      163       123        47 \n\n# Factor Sex\nsummary(df$sex)\n\nfemale   male \n   165    168 \n\n\nThe ‘species’ variable has 3 levels: Adelie, Chinstrap, and Gentoo. The number of individuals between the 3 levels is not balanced, with fewer individuals for the Chinstrap species. The ‘island’ variable has 3 levels: Biscoe, Drea,m, and Torgersen. The number of individuals between the 3 levels is not balanced, with fewer individuals for the Torgersen island. The ‘sex’ variable has 2 levels: female and male. The number of individuals per level is close to equilibrium.\n\n\n4.2.3 Analysis of potential relationships Y vs Xs\nWe can graphically analyse the possible relationships between Y and X. Please note that this graphical analysis of the relationships between Y and X does not predict the importance of the relationship. Statistical modeling is the only way to identify relationships.\n\npar(mfrow=c(2,2))\n# Species\nplot(df$body_mass_g~df$species,pch=16,col='darkblue',xlab='Espèces',ylab='Masse corporel en g')\n\n# Islands\nplot(df$body_mass_g~df$island,pch=16,col='darkblue',xlab='Îles',ylab='Masse corporel en g')\n\n# Sex\nplot(df$body_mass_g~df$sex,pch=16,col='darkblue',xlab='Sexe',ylab='Masse corporel en g')\n\n\n\n\nIn terms of species, we can see that Gentoo has a higher body mass (between 5000 and 6000g) than the other two species (between 3000 and 4000g). About the islands, we can see that the individuals present on Biscoe have a higher body mass (between 5000 and 6000g) than the individuals present on the other two islands (between 3000 and 4000g). Finally, in terms of sex, males appear to have a slightly higher body mass than females.\n\n\n4.2.4 Analysis of possible interactions between the three independent variables\nHere, we will consider the interaction between the three factors studied. To estimate the presence of interactive effects, we develop a graphical approach. Remember that the interaction between factors can only be tested if the factors are crossed (i.e. all the levels of one treatment are represented in all the levels of the other treatment and vice versa = a factorial design). This point must be tested first.\n\n# The experimental design means that the factors are cross-tabulated (all the levels of each variable are represented in all the levels of the other variables). \n\n# Interaction Species:Island:Sex\npar(mfrow=c(1,1))\nboxplot(df$body_mass_g~df$species*df$island*df$sex, \n        varwidth = TRUE, \n        xlab = \"Espèces.Îles.sexe\", ylab = \"Body mass (g)\", \n        col='blue2', main = \"\")\n\n\n\n\nExplications\n\n\n4.2.5 Check collinearity between X\nColinearity refers to the situation in which two or more predictors of collinearity are closely related to each other.The presence of collinearity can pose problems in the context of regression, as it can be difficult to separate the individual effects of collinear variables on the response.\nHere, we will test for collinearity between our 3 predictor variables:\n\n# ploting Species by Island\nplot1 &lt;- ggplot(df, aes(x=species, y=island)) +\n  geom_point() +\n  theme_bw()\n\n# ploting Species by Sex\nplot2 &lt;- ggplot(df, aes(x=species, y=sex)) +\n  geom_point() +\n  theme_bw() \n\n# ploting Island by Sex\nplot3 &lt;- ggplot(df, aes(x=island, y=sex)) +\n  geom_point() +\n  theme_bw()\n\n# Ploting side-by-side\nmarrangeGrob(list(plot1,plot2,plot3), nrow=1, ncol=3, top=NULL)\n\n\n\n\nIn our example, we can see that for the interaction between Species and Sex, there are two sex modalities per species, and for the interaction between Island and Sex, there are two sex modalities per island. However, for the interaction between Species and islands based on, not all the islands contain all the species! We cannot therefore test the influence of islands and species on the basis of this result. We therefore decided to remove the Island variable from our analysis. We will test the influence of species and sex on the body mass of penguins, always with years as a random effect.\n\n\n\n4.3 Statistical analysis\n\n4.3.1 Model construction\nFor statistical modelling, we first analyse the full model (model containing all the independent variables to be tested).\nTo obtain the candidate model (a model containing only the significant terms) from the full model, we will use the BACKWARD SELECTION METHOD, i.e. model selection based on the significance of the terms. In this approach, we start by creating the full model with all the variables of interest, then drop the least significant variable as long as it is not significant. We continue by successively fitting reduced models and applying the same rule until all the remaining variables are significant. The deletion of non-significant terms must follow the following two steps: - First, insignificant interactions are successively removed. - Secondly, the non-significant main effects are successively removed. A main effect is only removed if it is insignificant AND if it is not contained in a significant interaction.\nIn this example, we consider a measure of dependence at year level (e.g. a mass measurement made in 2009 depends on the measurement made in 2008, which in turn depends on the measurement made in 2007). The presence of the random effect of the year will be integrated not with the lm function, but lme (from the nlme package).\n\n# Full model\nmod1 = lme(body_mass_g~species\n              + sex\n              + species:sex\n              ,random=~1|year\n              ,data=df)\n\n# Then we check for significance\n#anova(mod1)\n\n#Anova Output\n#            numDF denDF  F-value p-value\n#(Intercept)     1   325 61569.82  &lt;.0001\n#species         2   325   758.36  &lt;.0001\n#sex             1   325   387.46  &lt;.0001\n#species:sex     2   325     8.76   2e-04\n\nWe can see from the anova output of our full model that each interaction and each variable is significant (&lt;0.05). The full model is therefore the candidate model.\n\n\n4.3.2 Model’s coefficients analysis\n\n# Coefficients of the model\nsummary(mod1)\n\nLinear mixed-effects model fit by REML\n  Data: df \n       AIC      BIC    logLik\n  4718.236 4748.556 -2351.118\n\nRandom effects:\n Formula: ~1 | year\n        (Intercept) Residual\nStdDev:  0.01402413 309.3973\n\nFixed effects:  body_mass_g ~ species + sex + species:sex \n                            Value Std.Error  DF  t-value p-value\n(Intercept)              3368.836  36.21222 325 93.03036  0.0000\nspeciesChinstrap          158.370  64.24029 325  2.46528  0.0142\nspeciesGentoo            1310.906  54.42228 325 24.08767  0.0000\nsexmale                   674.658  51.21181 325 13.17387  0.0000\nspeciesChinstrap:sexmale -262.893  90.84950 325 -2.89372  0.0041\nspeciesGentoo:sexmale     130.437  76.43559 325  1.70650  0.0889\n Correlation: \n                         (Intr) spcsCh spcsGn sexmal spcsC:\nspeciesChinstrap         -0.564                            \nspeciesGentoo            -0.665  0.375                     \nsexmale                  -0.707  0.399  0.471              \nspeciesChinstrap:sexmale  0.399 -0.707 -0.265 -0.564       \nspeciesGentoo:sexmale     0.474 -0.267 -0.712 -0.670  0.378\n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-2.67360404 -0.69157224  0.03564805  0.66744876  2.78292473 \n\nNumber of Observations: 333\nNumber of Groups: 3 \n\n# The output is:\n#Fixed effects:  body_mass_g ~ species + sex + species:sex \n#                            Value Std.Error  DF  t-value p-value\n#(Intercept)              3368.836  36.21222 325 93.03036  0.0000\n#speciesChinstrap          158.370  64.24029 325  2.46528  0.0142\n#speciesGentoo            1310.906  54.42228 325 24.08767  0.0000\n#sexmale                   674.658  51.21181 325 13.17387  0.0000\n#speciesChinstrap:sexmale -262.893  90.84950 325 -2.89372  0.0041\n#speciesGentoo:sexmale     130.437  76.43559 325  1.70650  0.0889\n\nFrom this table, we can determine the coefficients of the model such that:\nSpecies factor\n- \\(species_{Adelie}\\) = 0 (the baseline of the factor Habitat) - \\(Species_{Chinstrap}\\) = \\(158.370\\) - \\(Species_{Gentoo}\\) = \\(1310.906\\)\nSex factor\n- \\(Sex_{female}\\) = 0 (the baseline of the factor Habitat) - \\(Sex_{male}\\) = \\(674.658\\)\n**Interaction*\n- \\(Species_{Chinstrap}\\):\\(Sex_{male}\\) = \\(-262.893\\) - \\(Species_{Gentoo}\\):\\(Sex_{male}\\) = \\(130.437^{NS}\\)\nSo, the candidate model is: \\[  Species = 3369 + (Adelie = 0, Chinstrap = 158, Gentoo = 1311)  + (Female = 0,\\: Male = 675)\\] \\[       + (Adelie_{Male} = 0, \\:Chinstrap_{Male} = -263,\\: Gentoo_{Male} = 130^{NS}) \\]\nFor sake of simplicity, we can write the model depending on the sex:\nThe model for the Female pinguin is: \\[ Sex_{Female} = 3369\\:  + (Adelie = 0,\\: Chinstrap = 158,\\: Gentoo = 1311)\\]\nThe model for the Male pinguin is: \\[Sex_{Male} = 4043\\: + (Adelie = 0,\\: Chinstrap = - 105,\\: Gentoo = 1441)\\]\nThus, sex, species, and the interaction of these two variables (except between Male and Gentoo) do have a significant impact on penguin body mass. For example, in Adelie penguins, the female will have a body mass of 3369g, whereas a male will have a body mass of 4043g and in Chinstrap penguins, the female will have a body mass of 3527g, whereas a male will have a body mass of 3938g.\n\n\n\n4.4 Model validation\nTo validate the model, we need to : - Validate the normality of the residuals =&gt; Histogram and QQplot of the residuals - Validate the homogeneity of the variances - In addition, check for the presence of observations which would have contributed too much to the model.\n\n4.4.1 Normality of the residuals\n\npar(mfrow=c(1,2))\n# Histogram\nhist(mod1$residuals,col='blue',xlab=\"residuals\",main=\"Check Normality\")\n# Quantile-Quantile plot\nqqnorm(mod1$residuals,pch=16,col='blue',xlab='')\nqqline(mod1$residuals,col='red')\n\n\n\n\nWe can see that the histogram follows a normal distribution, and the quantile plot points follow the red line: the normality of the residuals is validated.\n\n\n4.4.2 Homogeneity of the variance\n\npar(mfrow=c(1,3))\n\n# residuals vs fitted\nplot(residuals(mod1)~fitted(mod1)\n      , col='blue'\n      , pch=16)\nabline(h = 0)\n\n# residuals against Species\nboxplot(residuals(mod1)~ df$species, \n         varwidth = TRUE,\n         ylab = \"Residuals\",\n         xlab = \"Species\",\n         main = \"\")\nabline(h = 0)\n\n# residuals against Sex\nboxplot(residuals(mod1)~ df$sex, \n         varwidth = TRUE,\n         ylab = \"Residuals\",\n         xlab = \"Sex\",\n         main = \"\")\nabline(h = 0)\n\n\n\n\nWe can see here that for each plot, the variance of the residuals is evenly distributed around the horizontal line. The homogeneity of the variance is validated.\n\n\n4.4.3 Look at influential observations\n\npar(mfrow = c(1, 1))\nCookD(mod1,newwd=TRUE)\n\nWe can see that individuals 314, 315 and 325 contribute slightly more to the model, but this is not an aberrant result."
  },
  {
    "objectID": "Mixed_models.html#references",
    "href": "Mixed_models.html#references",
    "title": "Mixed models in ecology",
    "section": "References",
    "text": "References\nThe chapter was partly inspired from “Modèle mixte, modélisation de la variance” (L. Bel et al. 2016), taking some of the examples to illustrate the various aspects of mixed models. Section 4 “Application” was adaptated from Yannick Outreman’s courses on linear mixed model."
  }
]