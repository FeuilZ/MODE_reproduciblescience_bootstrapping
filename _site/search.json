[
  {
    "objectID": "bayesian_modeles.html",
    "href": "bayesian_modeles.html",
    "title": "Introduction to bayesian modeles for ecology",
    "section": "",
    "text": "History of Bayesian concept.\nPhilosophy behind it. Frequentist approach : “What is the probability to observe my data given my model.”\n\nBayesian approach : “What is the probability of m y model given my data.”\nRappel : - différence entre loi à posterio jointes et marginales"
  },
  {
    "objectID": "bayesian_modeles.html#main-objective-for-context",
    "href": "bayesian_modeles.html#main-objective-for-context",
    "title": "Introduction to bayesian modeles for ecology",
    "section": "Main objective, for context",
    "text": "Main objective, for context\nFirst, let’s take an simple example to explain the idea behind Bayesian method. We want to estimate the mean abundance per \\(m^2\\) of one fungus in a forests. To do that, we set up it some sampling area in which we count the number of mushroom. We can simulate the data by taking random observations in a poisson distribution. Let’s suppose that our studies as 200 sampling area. Because it is count data, number of mushroom that we will count should follow a poisson distribution :\n\nn_sample = 200 # sampling area\nlbda = 5 # mean of poisson distribution\npois_distr = dpois(1:20, lambda = lbda)\nplot(pois_distr,type =\"h\",\n     lwd = 2, col = 'blue',\n     xlab = \"Mushroom Count\", \n     ylab = expression(paste( 'Density or ','[y]')) )\n\n\n\n\nTo simulate the sampling campaign we are taking values in this poisson distribution . In our case those will be used to estimate the mean number of mushroom in the forest.(\\(\\lambda = 5\\) is already known because we simulate the data, but in reality this is an unknown).\n\nset.seed(1000)\n\nY = rpois(n = n_sample, lambda = lbda)\n\nhist(Y)\n\n\n\n\nSo let’s pretend that we don’t know the \\(\\lambda\\). We want to find the the value of the mean number of mushroom we will call \\(\\hat{\\lambda}\\) and we also want to know the probability of this \\(\\hat{\\lambda}\\). In fact the Bayesian method will give us the multiple estimated mean \\(\\hat{\\lambda}\\) and the probability of those value to be true knowing the observation \\(Y\\). We can simply write this as follow \\([\\hat{\\lambda} \\mid Y]\\) which is the probability of hat lambda knowing our observations. This probability can be found with the equation :\n\\[\n[\\hat{\\lambda} \\mid Y] = [Y \\mid \\hat{\\lambda}  ]\\cdot[\\hat{\\lambda}]\n\\]\nThe two component of the right hand side of the equation are \\([Y \\mid \\hat{\\lambda} ]\\) the likelihood of our data and \\([\\hat{\\lambda}]\\) the prior distribution. First lets start with the likelihood. Our data follow a poisson distribution so our likelihood will follow a poisson distribution :\n\\[\nL(\\hat{\\lambda} ; y)=[y \\mid \\hat{\\lambda}] = \\frac{e^{-\\hat{\\lambda}} \\cdot\\hat{\\lambda}^{y}}{y!}\n\\]\nThis a first good step, but there is a small issue here, this formula isn’t completely usable in this form. This is because it can only take one observation. In english words it is like asking what is the probability of one observation (one count of mushroom) given a model with a mean \\(\\hat{\\lambda}\\). It it clear that this form isn’t powerful enough because it use only one observation. What we want is to use all the data that we have, we want to know the probability of all the observations given a model with a mean \\(\\hat{\\lambda}\\). To do so we can write the likelihood of all our data \\(Y\\) as the product of the likelihood of each observation \\(y_i\\). (We are allowed to do this only because observations are independent)\n\\[\n\\begin{align}\n[Y \\mid \\hat{\\lambda}] &= \\prod^{n}_{i=1}[y_i \\mid \\hat{\\lambda}] \\\\\n&=\\prod^{n}_{i=1}\\frac{e^{-\\hat{\\lambda}} \\cdot\\hat{\\lambda}^{y_i}}{y_i!} \\\\\n&\\propto \\prod^{n}_{i=1}e^{-\\hat{\\lambda}} \\cdot\\hat{\\lambda}^{y_i}\\\\\n\\end{align}\n\\]\nAs you can see we don’t keep the \\(\\frac{1}{y_i!}\\), it is because we are only interested in the terms that are impacted by \\(\\hat{\\lambda}\\). The last form which is proportional to the likelihood function have a more convenient form for the next step. Lets rearrange the function in a more convenient form\n\\[\n\\begin{align}\n\\prod^{n}_{i=1}e^{-\\hat{\\lambda}} \\cdot\\hat{\\lambda}^{y_i}&= e^{-n \\cdot\\hat{\\lambda}} \\cdot\\hat{\\lambda}^{\\sum^{n}_{i=1} y_i}\\\\\n&= e^{-n \\cdot\\hat{\\lambda}} \\cdot\\hat{\\lambda}^{n \\cdot \\bar{y}}\\\\\n\\end{align}\n\\]\nThe fist line just use the power/exponential multiplication properties. The second line is just a writing simplification that is common in other resources, \\(mean(y)=\\bar{y} = \\frac{1}{n}\\sum_{i=1}^n y_i \\Rightarrow n\\cdot \\bar{y} = \\hat{\\lambda}^{\\sum^{n}_{i=1} y_i}\\).\nNow we want to find the prior distribution of \\(\\hat{\\lambda}\\). Fist we have to choose the distribution family of our prior. We will use a Gamma distribution. We are using this one because it let the prior and the posterior have the same distribution family, it is called conjugate distributions. The the prior is called a conjugate prior for the likelihood function. Which mean that the prior function and the likelihood function have the same form ! And this means that we can simplify ! lets try it :\n\\[\n\\begin{align}\n[\\hat{\\lambda}]&\\sim Gamma(\\lambda,\\alpha_p,\\beta_p) \\\\\n&= \\lambda^{\\alpha_p -1}\\frac{\\beta_p^\\alpha\\cdot e^{-\\beta_p \\lambda}}{\\Gamma(\\alpha_p)} \\propto \\lambda^{\\alpha_p -1} \\cdot e^{-\\beta_p \\lambda}\n\\end{align}\n\\]\nSame as the likelihood, we are only interested by the term that vary with \\(\\hat{\\lambda}\\) so we remove \\(\\frac{\\beta^\\alpha}{\\Gamma(\\alpha)}\\) and keep the proportional formula of the prior. We can now find real formula of our posterior distribution.\n\\[\n\\begin{align}\n[\\lambda \\mid y] &= [y \\mid \\lambda]\\cdot[\\lambda] \\\\\n[\\lambda \\mid y] &\\propto e^{-n \\cdot\\lambda} \\cdot\\lambda^{n \\cdot \\bar{y}} \\cdot \\lambda^{\\alpha_p -1} \\cdot e^{-\\beta_p \\lambda}\\\\\n[\\lambda \\mid y] &\\propto e^{-\\beta_p \\lambda-n\\lambda} \\cdot\\lambda^{n\\bar{y}+\\alpha_p -1} \\\\\n[\\lambda \\mid y] &\\propto e^{-\\lambda (\\beta_p +n)} \\cdot\\lambda^{n\\bar{y}+\\alpha_p -1}\\\\\n\\end{align}\n\\]\nDo the last formula remind you something familiar ? That’s right it is a Gamma distribution ! This is the magic of the conjugate distributions. We can now write :\n\\[\n\\begin{align}\n[\\lambda \\mid y] &\\propto e^{-\\lambda \\beta} \\cdot\\lambda^{\\alpha -1}\\\\\n[\\lambda \\mid y] &\\sim Gamma(\\alpha_p +n\\bar{y}, \\beta_p +n)\n\\end{align}\n\\]\nWe can do some simulations to show the results. We are looking for the probability of \\(\\hat{\\lambda}\\), so for the computation we create a vector of all \\(\\hat{\\lambda}\\) for which we want to know the probability:\n\nlambda_hat &lt;- seq(0,10, by = 0.01)\n\nAnd now, in order to compare them, we compute the distribution of the prior and the posterior (which are both following a gamma distribution) with an increasing amount of sample:\n\nalph = 1\nbet= 1\n\npar(mfrow = c(2,3))\nn_obs = 0\nfor(n_obs in list(0,1:5,1:10,1:50,1:100,1:200)){\n\n  \n  # prior distribution\n  l_prior = dgamma(lambda_hat, shape = alph, rate = bet)\n  \n  # posterior distribution\n  l_post = dgamma(lambda_hat, shape =  alph + sum(Y[n_obs]), rate = bet + max(n_obs))\n  \n  plot(lambda_hat,l_prior, ylim = c(0,max(c(l_post,l_prior))),\n       type = 'l', lwd = 2, col = 'orange',\n       xlab = expression(lambda), \n       ylab = expression(paste('[', lambda, '|y]')) )\n  \n  \n  lines(lambda_hat,l_post, type = 'l',lty = 3, lwd = 2, col = 'purple')\n  abline(v = 5, lty = 2, lwd = 2)\n  \n  title(paste(\"n = \",max(n_obs)))\n\n}\n\n\n\n\nWhen we add no data in the computation of the posterior, it is normal that we don’t see any modifications from the prior. Adding 5 observation already bring some good information, the prior and the posterior have no longer the same shape and we have a better estimation of the true \\(\\lambda\\). Increase the number of data give us a better approximation of the true mean. The density of probability is also higher with a lot fo data, because we have more confidence in the approximation."
  },
  {
    "objectID": "bayesian_modeles.html#approximation-with-mcmc",
    "href": "bayesian_modeles.html#approximation-with-mcmc",
    "title": "Introduction to bayesian modeles for ecology",
    "section": "Approximation with MCMC",
    "text": "Approximation with MCMC\nIl existe de multiple algorithmes de type MCMC ( Metropolis-Hastings, échantillionneur de Gibbs, Hamiltonian Monte Carlo), chacun possèdes ses avantages et ses inconvénients et le choix de l’algorithme dépend de la situation d’application. Cependant ils partent tous de la même base théorique.\nL’idée essentielle de la MCMC est que nous pouvons en apprendre davantage sur les paramètres non observés en effectuant de nombreux tirages aléatoires dans leurs distributions marginales a posteriori. L’accumulation de ces nombreux échantillons donne la “forme” de la distribution postérieure. Ces nombreux échantillons nous permettent de calculer les quantités qui nous intéressent : moyennes, variances et quantiles.\nIl est maintenant légitime de se demander : Mais ça sert à quoi de tirer un échantillionnage dans une loi inconnu pour ensuite la reconstituer ? Et surtout comment on fait si on ne la connait pas ?\nEt bien la loi que l’on reconstitue n’est pas totalement la même que celle qu’on utilise pour obtenir ces tirages. En effet la loi a posteriori n’est pas totalement inconnue. Ses informations sont portées par le produit de vraissemblance et du prior :\n\\[\n[{\\theta} \\mid Y] \\propto [Y \\mid {\\theta}  ]\\cdot[{\\theta}]\n\\]\nC’est cette loi a priori estimée qui sert de première référence et le tirage aléatoire va permettre de normaliser cette expression pour qu’elle soit égal à un fonction de probabilité dont l’intégral est égal à 1. Cette propriété est normalement donnée par la division du produit par \\([Y]\\).\nL’algorithme MCMC estime donc la loi a posteriori des paramètres non observé en évitant l’étape de calcul d’intégral qui peut s’avérer complexe pour obtenir \\([Y]\\).\nStep 1 : Initialisation\n\nA small example without using JAGS\nOn reprend l’exemple avec les champignons.\n\n# [y | lambda]\n\nlikelihood = function(lambda,y){\n  if(lambda &lt; 0){\n    return(0)\n  }else{\n    return( dpois(x = sum(y),lambda = lambda*length(y)))\n  }\n}\n\n# [lambda]\nprior.dist = function(lambda){\n  dunif(lambda,0,1000)\n}\n\n# g([lambda_c(i) | lambda(i-1)])\ndstep &lt;- function(lambda1, lambda2, sd.explore = 0.1){\n  dnorm(lambda2, mean = lambda1, sd = sd.explore)\n}\n\nrstep &lt;- function(lambda, sd.explore = 0.1){\n  rnorm(1, mean = lambda, sd = sd.explore)\n}\n\nMH.ratio &lt;- function(lambda_c,lambda, y){\n  ratio = (likelihood(lambda_c, y) * prior.dist(lambda) * dstep(lambda, lambda_c))/\n    (likelihood(lambda, y) * prior.dist(lambda) * dstep(lambda_c, lambda))\n  \n  return(ratio)\n}\n\n\nmcmc.function = function(lambda_init, n_iter = 10000, burning = 100, thin = 10){\n  \n  lambda_sample = rep(NA, n_iter)\n  lambda_save = rep(NA, n_iter)\n  lambda_sample[1] = lambda_init\n  i=2\n  for(i in 2:n_iter){\n    lambda = lambda_sample[(i-1)]\n    lambda_c = rstep(lambda)\n    \n    ratio = MH.ratio(lambda_c,lambda, Y)\n    \n\n    if(runif(1)&lt;ratio){\n      lambda_sample[i] = lambda_c\n    }else{\n      lambda_sample[i] = lambda\n    }\n    \n  }\n  lambda_save = lambda_sample[seq(burning,n_iter, by= thin)]\n  return(data.frame(iteration = 1:length(lambda_save),\n                    step = lambda_save))\n}\n\n\nmcmc_df = mcmc.function(lambda_init = 10,burning = 200, n_iter = 1000000)\n\nplot(step~iteration, mcmc_df, \"l\")"
  },
  {
    "objectID": "bayesian_modeles.html#implémentation-de-lalgorithm-de-metropolis-hastings",
    "href": "bayesian_modeles.html#implémentation-de-lalgorithm-de-metropolis-hastings",
    "title": "Introduction to bayesian modeles for ecology",
    "section": "Implémentation de l’algorithm de Metropolis-Hastings",
    "text": "Implémentation de l’algorithm de Metropolis-Hastings\nLet’s implemant the algortihm to try to understand how it works. Dans les lignes suivantes nous allons décrire les différentes étapes de l’algorithme de Matropolis-Hastings avec les lignes de codes R correspondantes.\n#Step 1 : Definition of the likelihood function and the prior law Comme pour chaque début d’analyse statistique bayésienne, on pause le problème et on définit la loi de probabilité de la vraissemblance et les loi à priori des paramètres à estimer.\nIci on reprend le problème de nos comptages de champignions, on choisit donc une loi de poisson pour la vraissemblance. Et cette fois ci pour l’estimation du paramètre \\(\\lambda\\) on choisi un loi uniforme allant de \\(0\\) à \\(1000\\) . On fait donc l’hypothèse de n’avoir aucun information sur le paramètre \\(\\lambda\\). Aucune information n’est porté par le prior.\n\n# [y | lambda]\n\nlikelihood = function(lambda,y){\n    return( dpois(x = sum(y),lambda = lambda*length(y)))\n}\n\n\n# [lambda]\nprior.dist = function(lambda){\n  dunif(lambda,0,1000)\n}\n\nStep 2 : Definition of a candidate position\nOn va chercher à se déplacer il faut donc définir une fonction pour dertimer une position candidat. On tire ici aléatoirement cette position dans une loi normal de moyenne \\(\\lambda_c\\) c’est à dire la position à laquelle on part et on choisit abitrairement une valeur d’écart-type.\n\nmove  &lt;- function(lambda, sd.explore = 0.1){\n  candidate &lt;- rnorm(1, mean = lambda, sd = sd.explore)\n  return (candidate)\n}\n\nStep 3 : Compute of the ratio\nUne fois qu’on a cette position candidat il faut décider si si on la garde ou pas, le critère de décision à calculer est la ratio de Metropolis-Hastings \\(r\\). On p\n\\[\nr = \\dfrac{[\\lambda_{t+1} \\mid Y]\\space \\cdot \\space [\\lambda_{t+1}] \\space \\cdot \\space g(\\lambda_{t+1} \\mid \\lambda_{t})}{[\\lambda_{t} \\mid Y]\\space \\cdot \\space [\\lambda_{t}] \\space \\cdot \\space g(\\lambda_{t} \\mid \\lambda_{t+1})}\n\\]\navec \\(g(\\lambda_{t+1} \\mid \\lambda_{t})\\) la probabilité de passer de la position candidate sachant la position courante.\n\nproba_move &lt;- function(lambda1, lambda2, sd.explore = 0.1){\n  dnorm(lambda2, mean = lambda1, sd = sd.explore)\n} \n\n\nMH.ratio &lt;- function(lambda_c,lambda, y){\n  ratio = (likelihood(lambda_c, y) * prior.dist(lambda) * proba_move(lambda, lambda_c))/\n    (likelihood(lambda, y) * prior.dist(lambda) * proba_move(lambda_c, lambda))\n  \n  return(ratio)\n}\n\nStep 4 : Decide if we go to the candidate position or not\nPour décider si on passe à la position candidate \\(\\lambda_{t+1}\\) on défini \\(u\\) : \\[\nu \\sim unif(0,100)\n\\]\nSi il est supérieur au ratio \\(r\\) on reste sur la position courante et inversement si \\(u\\) est inférieur à \\(r\\) on passe à la position candidate.\nFonction qui permet de regrouper tout les calculs :\n\nmcmc.function = function(lambda_init, n_iter = 1000, burning = 100, thin = 10){\n  \n  lambda_sample = rep(NA, n_iter)\n  lambda_save = rep(NA, n_iter)\n  lambda_sample[1] = lambda_init\n  i=2\n  for(i in 2:n_iter){\n    lambda = lambda_sample[(i-1)]\n    lambda_c = move(lambda)\n    \n    ratio = MH.ratio(lambda_c,lambda, Y)\n    \n\n    if(runif(1)&lt;ratio){\n      lambda_sample[i] = lambda_c\n    }else{\n      lambda_sample[i] = lambda\n    }\n    \n  }\n  lambda_save = lambda_sample[seq(burning,n_iter, by= thin)]\n  return(data.frame(iteration = 1:length(lambda_save),\n                    step = lambda_save))\n}\n\nIl y a un parmètre dont on n’a pas discuter dans cette fonction c’est le \\(thin\\), il signifie qu’on ne va sauvegarder les échantillionnage au sein de la chaine avec un interval égal à \\(thin\\). C’est dû au fait que les échantillion sont corrélé entre eux car dépendant dans la position précédente et donc ne reflète donc pas correctement la distribution. Par conséquent, si l’on souhaite avoir des échantillons indépendants, on doit éliminer la majorité des échantillons pour ne conserver qu’un échantillon tous les \\(thin\\) pas, avec \\(thin\\) « suffisamment grand ».\nStep 5 : Visualization\n\nmcmc_df = mcmc.function(lambda_init = 10,burning = 200, n_iter = 5000)\n\nplot(step~iteration, mcmc_df, \"l\")\n\n\n\np1 &lt;- ggplot(data = mcmc_df)+\n  geom_histogram(aes(x = step))+\n  theme_bw()\n\nalph = 1\nbet= 1\n\nposterior_exact &lt;- tibble(p = seq(0,5, length.out = 10001)) %&gt;% \n  mutate(posterior = dgamma(p, shape =  alph + sum(Y), rate = bet + 5000))\np1 + geom_line(data = posterior_exact, aes(x=p, y =posterior), col = 'red')\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nLe premier graphique représante"
  },
  {
    "objectID": "bayesian_modeles.html#discussion-with-two-parameters",
    "href": "bayesian_modeles.html#discussion-with-two-parameters",
    "title": "Introduction to bayesian modeles for ecology",
    "section": "Discussion with two parameters",
    "text": "Discussion with two parameters"
  },
  {
    "objectID": "bayesian_modeles.html#some-words-about-rjags",
    "href": "bayesian_modeles.html#some-words-about-rjags",
    "title": "Introduction to bayesian modeles for ecology",
    "section": "Some words about Rjags",
    "text": "Some words about Rjags\nAprès une implémentation from scratch de l’algorithme de Metropolis Hastings il est temps de vous annoncer qu’il existe des outils qui permettent de réaliser tout ceci. Un de plus courrament utilisé c’est RJags…"
  },
  {
    "objectID": "bayesian_modeles.html#iv-1-the-role-of-prior-knowledge-and-beliefs",
    "href": "bayesian_modeles.html#iv-1-the-role-of-prior-knowledge-and-beliefs",
    "title": "Introduction to bayesian modeles for ecology",
    "section": "IV-1) The role of prior knowledge and beliefs",
    "text": "IV-1) The role of prior knowledge and beliefs\nIn Bayesian statistics, prior knowledge and beliefs play a central role in the formulation and interpretation of Bayesian models. As explained before, the fundamentals of Bayesian inference lies in combining prior information with observed data to obtain updated or posterior probabilities.\nIncorporating existing information to a data set can be based on previous studies, expert opinions, historical data or simply known subjective beliefs. It will allow the future model to avoid over-fitting and favor a more plausible and simple estimation."
  },
  {
    "objectID": "bayesian_modeles.html#iv-2-informative-and-non-informative-priors",
    "href": "bayesian_modeles.html#iv-2-informative-and-non-informative-priors",
    "title": "Introduction to bayesian modeles for ecology",
    "section": "IV-2) Informative and non-informative priors",
    "text": "IV-2) Informative and non-informative priors"
  },
  {
    "objectID": "bayesian_modeles.html#iv-3-incorporating-expert-opinions-and-literature-data",
    "href": "bayesian_modeles.html#iv-3-incorporating-expert-opinions-and-literature-data",
    "title": "Introduction to bayesian modeles for ecology",
    "section": "IV-3) Incorporating expert opinions and literature data",
    "text": "IV-3) Incorporating expert opinions and literature data"
  },
  {
    "objectID": "bayesian_modeles.html#v-1-highlighting-specific-ecological-studies-that-employed-bayesian-methods",
    "href": "bayesian_modeles.html#v-1-highlighting-specific-ecological-studies-that-employed-bayesian-methods",
    "title": "Introduction to bayesian modeles for ecology",
    "section": "V-1) Highlighting specific ecological studies that employed Bayesian methods",
    "text": "V-1) Highlighting specific ecological studies that employed Bayesian methods"
  },
  {
    "objectID": "bayesian_modeles.html#v-2-illustrative-examples-from-different-ecological-sub-disciplines",
    "href": "bayesian_modeles.html#v-2-illustrative-examples-from-different-ecological-sub-disciplines",
    "title": "Introduction to bayesian modeles for ecology",
    "section": "V-2) Illustrative examples from different ecological sub-disciplines",
    "text": "V-2) Illustrative examples from different ecological sub-disciplines"
  }
]